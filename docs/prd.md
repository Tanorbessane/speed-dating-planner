# Syst√®me d'Optimisation de Tables Rotatives - Product Requirements Document (PRD)

---

## Goals and Background Context

### Goals

- Cr√©er un syst√®me d'optimisation de planification pour √©v√©nements de networking/speed dating permettant de maximiser les rencontres uniques entre participants
- Garantir une √©quit√© stricte dans l'exp√©rience (chaque participant rencontre un nombre similaire de personnes ¬±1)
- Assurer une performance scalable pour 300-1000 participants avec g√©n√©ration de planning en moins de 10 secondes
- Fournir une gestion robuste des cas r√©els (retardataires, abandons, tables de tailles variables)
- Produire des exports exploitables (CSV/JSON) pour int√©gration avec syst√®mes √©v√©nementiels existants

### Background Context

Le probl√®me de l'optimisation des rencontres lors d'√©v√©nements de networking est un d√©fi combinatoire complexe connu sous le nom de Social Golfer Problem g√©n√©ralis√©. Les organisateurs d'√©v√©nements ont besoin d'un outil capable de r√©partir automatiquement N participants sur X tables (capacit√© maximale x personnes) durant S sessions, tout en maximisant la diversit√© des rencontres et en minimisant les r√©p√©titions de paires.

Les solutions existantes soit ne garantissent pas l'√©quit√© entre participants, soit ne sont pas scalables, soit ne g√®rent pas les contraintes pratiques des √©v√©nements r√©els (tables non-pleines, participants en retard). Ce projet vise √† cr√©er une solution pragmatique bas√©e sur une architecture hybride √† 3 couches : g√©n√©ration rapide d'un planning de base (round-robin), am√©lioration heuristique pour r√©duire les r√©p√©titions, et post-traitement pour garantir l'√©quit√© individuelle.

### Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-10 | 1.0 | Version initiale du PRD bas√©e sur session de brainstorming | John (PM) |

---

## Requirements

### Functional Requirements

#### üéØ Core MVP Requirements

**FR1:** Le syst√®me doit accepter en entr√©e les param√®tres N (nombre de participants ‚â•2), X (nombre de tables ‚â•1), x (capacit√© maximale par table ‚â•2), et S (nombre de sessions ‚â•1).

**FR2:** Le syst√®me doit valider que X √ó x ‚â• N (capacit√© totale suffisante pour tous les participants), sinon retourner une erreur explicite.

**FR3:** Le syst√®me doit g√©n√©rer un planning complet assignant chaque participant √† exactement une table par session, pour toutes les S sessions.

**FR4:** Le syst√®me doit maximiser le nombre total de paires uniques de participants se rencontrant √† travers toutes les sessions.

**FR5:** Le syst√®me doit minimiser le nombre total de r√©p√©titions de paires (deux participants assign√©s √† la m√™me table plus d'une fois).

**FR6:** Le syst√®me doit garantir une √©quit√© individuelle : l'√©cart entre le nombre de rencontres uniques du participant ayant rencontr√© le plus de monde et celui en ayant rencontr√© le moins ne doit pas exc√©der 1 personne.

**FR7:** Le syst√®me doit g√©rer les tables de tailles variables lorsque N n'est pas un multiple exact de x, en r√©partissant les participants de sorte que la diff√©rence de taille entre la plus grande et la plus petite table ne d√©passe jamais 1 personne par session.

**FR8:** Le syst√®me doit calculer et retourner les m√©triques de qualit√© suivantes pour chaque planning g√©n√©r√© :
- Nombre total de paires uniques cr√©√©es
- Nombre total de r√©p√©titions de paires
- Pour chaque participant : nombre de personnes uniques rencontr√©es

**FR9:** Le syst√®me doit calculer et retourner les statistiques d'√©quit√© suivantes :
- Minimum, maximum, moyenne et √©cart-type des rencontres uniques par participant
- Distribution des tailles de tables par session

**FR10:** Le syst√®me doit exporter le planning au format CSV avec les colonnes exactes : `session_id` (entier), `table_id` (entier), `participant_id` (entier).

**FR11:** Le syst√®me doit exporter le planning au format JSON avec la structure : `{"sessions": [{"session_id": int, "tables": [{"table_id": int, "participants": [int]}]}]}`

#### üîÆ Enhanced Features (Post-MVP or Optional)

**FR12:** Le syst√®me doit d√©tecter les configurations math√©matiquement impossibles pour z√©ro r√©p√©tition (quand S √ó (x-1) < N-1) et en informer l'utilisateur.

**FR13:** Pour les configurations impossibles, le syst√®me doit g√©n√©rer le planning minimisant les r√©p√©titions tout en garantissant une r√©partition √©quitable des r√©p√©titions (aucun participant ne doit subir significativement plus de r√©p√©titions que les autres).

**FR14:** Le syst√®me doit permettre l'ajout dynamique d'un participant retardataire √† partir d'une session donn√©e, avec recalcul des sessions futures uniquement.

**FR15:** Le syst√®me doit permettre la gestion d'un abandon de participant √† partir d'une session donn√©e, avec recalcul des sessions futures uniquement.

**FR16:** Le syst√®me doit permettre la configuration des priorit√©s d'optimisation (poids relatifs : rencontres uniques, √©quit√©, √©quilibrage des tables) via un fichier de configuration optionnel.

### Non-Functional Requirements

**NFR1:** Le syst√®me doit g√©n√©rer un planning pour N‚â§100 participants en moins de 2 secondes (cible de performance confortable).

**NFR2:** Le syst√®me doit g√©n√©rer un planning pour N‚â§300 participants en moins de 5 secondes (cible de performance standard).

**NFR3:** Le syst√®me doit g√©n√©rer un planning pour N‚â§1000 participants en moins de 30 secondes (cible de performance maximale acceptable).

**NFR4:** Le syst√®me doit utiliser une empreinte m√©moire ne d√©passant pas O(N¬≤) dans le pire cas pour le stockage de l'historique des rencontres.

**NFR5:** Le syst√®me doit √™tre impl√©ment√© en Python 3.10 ou sup√©rieur avec type hints complets pour toutes les fonctions publiques.

**NFR6:** Le code doit atteindre une couverture de tests unitaires et d'int√©gration d'au moins 85% avec pytest.

**NFR7:** Le syst√®me doit fournir une interface en ligne de commande (CLI) acceptant les param√®tres : `--participants N`, `--tables X`, `--capacity x`, `--sessions S`, `--output fichier`, `--format {csv|json}`, `--config fichier` (optionnel).

**NFR8:** Le syst√®me doit logger les √©tapes principales de g√©n√©ration (baseline, am√©lioration, √©quit√©) avec niveaux INFO, WARNING, ERROR appropri√©s.

**NFR9:** Le syst√®me doit avoir une architecture modulaire permettant de tester ind√©pendamment : la g√©n√©ration de baseline, l'am√©lioration locale, et l'enforcement d'√©quit√©.

**NFR10:** Le syst√®me doit valider toutes les entr√©es et retourner des messages d'erreur explicites en fran√ßais pour :
- Param√®tres hors limites (N‚â§0, X‚â§0, x‚â§1, S‚â§0)
- Capacit√© insuffisante (X √ó x < N)
- Formats de fichiers invalides

**NFR11:** Le syst√®me doit g√©n√©rer des plannings reproductibles : √† entr√©es identiques et seed al√©atoire fixe, le syst√®me doit produire le m√™me planning.

**NFR12:** La documentation utilisateur doit inclure des exemples concrets pour au moins 3 configurations typiques : petit √©v√©nement (N=30), moyen √©v√©nement (N=100), grand √©v√©nement (N=300).

---

## User Interface Design Goals

### Overall UX Vision

L'exp√©rience utilisateur privil√©gie la simplicit√© et l'efficacit√© pour les organisateurs d'√©v√©nements techniques. L'interface principale est une CLI permettant une int√©gration facile dans des workflows automatis√©s ou des scripts. Des visualisations optionnelles (notebook Jupyter, exports graphiques) permettent de valider la qualit√© des plannings g√©n√©r√©s et de communiquer les r√©sultats aux parties prenantes.

### Key Interaction Paradigms

- **CLI-first** : Toutes les fonctionnalit√©s accessibles via ligne de commande avec arguments explicites
- **Configuration as Code** : Param√®tres complexes via fichiers YAML/JSON pour reproductibilit√©
- **Progressive disclosure** : Affichage minimal par d√©faut (m√©triques cl√©s), mode verbose optionnel pour debugging
- **Export-oriented** : Outputs standardis√©s (CSV/JSON) pour int√©gration avec outils tiers (apps √©v√©nement, badges, etc.)

### Core Screens and Views

1. **CLI Interface** : Interface principale pour g√©n√©ration de planning
2. **Console Output** : Affichage des m√©triques de qualit√© et statistiques d'√©quit√© en temps r√©el
3. **Notebook Jupyter (Optionnel)** : Environnement interactif pour exploration et visualisation
4. **Visualisation Heatmap (Optionnel)** : Matrice de rencontres pour validation visuelle de la qualit√©

### Accessibility

Aucune exigence d'accessibilit√© formelle pour le MVP (outil CLI). La sortie console doit √™tre lisible dans des terminaux standards avec support UTF-8 pour caract√®res fran√ßais.

### Branding

Aucun branding sp√©cifique requis pour le MVP. L'outil est utilitaire et technique.

### Target Device and Platforms

**Plateformes principales :**
- Terminal/Console (Linux, macOS, Windows avec WSL)
- Jupyter Notebook (environnement Python standard)

**Pas de support pr√©vu pour :**
- Applications mobiles
- Interfaces web (sauf exploration future)

---

## Technical Assumptions

### Repository Structure: **Monorepo**

**D√©cision :** Monorepo unique contenant code source, tests, documentation et exemples.

**Rationale :** Projet autonome sans d√©pendances inter-services. Simplicit√© de gestion et facilit√© de contribution.

---

### Service Architecture

**Architecture :** Application Python standalone monolithique (outil CLI).

**Contraintes architecturales obligatoires :**

1. **Architecture modulaire en pipeline** : Le syst√®me doit suivre une architecture en pipeline avec au minimum 3 phases distinctes et testables ind√©pendamment :
   - Phase de g√©n√©ration d'un planning initial valide
   - Phase d'optimisation/am√©lioration de la qualit√©
   - Phase de validation/enforcement des contraintes d'√©quit√©

2. **S√©paration des pr√©occupations** : Chaque phase doit √™tre dans un module s√©par√© avec interfaces claires (pas de d√©pendances circulaires).

3. **Inversion de d√©pendances** : Les modules de bas niveau (g√©n√©ration) ne doivent pas d√©pendre des modules de haut niveau (CLI, export).

**Libert√© de l'Architect :** La structure exacte des modules, les noms de fichiers, et les patterns d'impl√©mentation (Strategy, Factory, etc.) sont √† la discr√©tion de l'Architect.

**Pas d'architecture distribu√©e, pas de services externes, pas de base de donn√©es** - tout en m√©moire.

---

### Testing Requirements

**Strat√©gie :** Full Testing Pyramid (unitaires + int√©gration + performance)

**Contraintes quantitatives :**
- Couverture de tests ‚â•85% (NFR6)
- Temps d'ex√©cution suite de tests <30s (pour CI rapide)
- Tests de performance obligatoires pour valider NFR1-NFR3

**Framework :** pytest (standard Python, riche √©cosyst√®me de plugins)

**Fixtures obligatoires :** Configurations de r√©f√©rence pour N=30, N=100, N=300 avec r√©sultats attendus pour tests de r√©gression.

**Tests de propri√©t√©s (optionnel mais recommand√©) :** Utilisation de hypothesis pour g√©n√©rer des cas de test al√©atoires et v√©rifier les invariants (√©quit√© ¬±1, validit√© du planning, etc.).

---

### Core Technical Stack

**Langage :** Python 3.10 minimum

**Rationale :**
- 3.10+ pour match/case, meilleurs messages d'erreur, union types am√©lior√©s
- Largement adopt√© (pas trop r√©cent), bon support dans CI/CD
- Pas 3.11+ car peut limiter adoption (certains environnements encore sur 3.10)

**Compatibilit√© OS :**
- Linux (prioritaire)
- macOS (support natif)
- Windows via WSL2 minimum (natif si faisable sans effort)

**D√©pendances externes MVP :** AUCUNE en dehors de la stdlib Python

**Rationale :**
- Maximise portabilit√© et facilit√© d'installation
- R√©duit surface d'attaque (vuln√©rabilit√©s)
- Simplifie maintenance

**D√©pendances dev/test :**
- `pytest` : Tests
- `pytest-cov` : Couverture
- `black` : Formatage automatique
- `ruff` : Linting rapide (remplace flake8, isort, etc.)
- `mypy` : Type checking statique

**D√©pendances optionnelles post-MVP :**
- `ortools` : Mode exact CSP/SAT (FR12-FR13 am√©lior√©s) - **Epic futur distinct**
- `matplotlib` : Visualisations (notebook Jupyter) - **Epic futur distinct**
- `pyyaml` : Parsing config avanc√©e (FR16) - **Seulement si FR16 impl√©ment√©**

---

### Development Environment & Tooling

**Gestionnaire de d√©pendances :** Poetry (recommand√©) ou pip + requirements.txt

**Rationale Poetry :**
- Gestion moderne (lock files, r√©solution d√©pendances)
- Build et publish PyPI simplifi√©s
- Standard de facto pour projets Python modernes

**Alternative acceptable :** pip + requirements.txt si contraintes d'environnement (simplicit√© extr√™me privil√©gi√©e)

**Code Quality Enforcement :**
- `black` (formatage) : ligne 88 caract√®res, style standard
- `ruff` (linting) : configuration stricte, pas de warnings tol√©r√©s
- `mypy` (type checking) : mode strict, tous les types v√©rifi√©s
- Pre-commit hooks obligatoires en dev

**Git Workflow :**
- Branches feature, PRs obligatoires
- Commits conventionnels (feat, fix, docs, test, refactor)
- Pas de commits directs sur `main`

---

### CI/CD & Automation

**Plateforme CI/CD :** GitHub Actions (si h√©berg√© sur GitHub) ou √©quivalent

**Pipeline obligatoire :**
1. **Tests** : Ex√©cution suite compl√®te sur Python 3.10, 3.11, 3.12
2. **Linting** : black --check, ruff, mypy
3. **Coverage** : V√©rification seuil 85%, g√©n√©ration rapport
4. **Performance** : Benchmarks sur instances de r√©f√©rence, d√©tection r√©gression

**D√©clencheurs :**
- Sur chaque PR (tous les checks)
- Sur merge main (tous les checks + optionnel: publish test PyPI)

**Artifacts :**
- Rapport de couverture (HTML)
- R√©sultats benchmarks (JSON)

---

### Packaging & Distribution

**Format :** Package Python standard (wheel + source distribution)

**Distribution MVP :**
- Installation via `pip install -e .` (mode d√©veloppement)
- Pas de publication PyPI pour MVP (distribution interne ou Git clone)

**Distribution future :**
- Publication PyPI quand stable (v1.0+)
- Versioning s√©mantique strict (MAJOR.MINOR.PATCH)

**Point d'entr√©e CLI :**
- Script entry point d√©fini dans `pyproject.toml` ou `setup.py`
- Commande globale : `speed-dating-planner` ou `sdp` (√† d√©finir)

---

### Configuration & Extensibility

**Configuration utilisateur :**
- Arguments CLI prioritaires (NFR7)
- Fichier de config optionnel (format YAML ou JSON, √† d√©cider par Architect)
- Variables d'environnement pour debugging (ex: `SDP_LOG_LEVEL=DEBUG`)

**Principes de configuration :**
- Convention over configuration (defaults sensibles)
- Validation stricte des configs (erreurs explicites si invalide)
- Pas de config globale syst√®me (tout local au projet/ex√©cution)

**Extensibilit√© future :**
- Architecture doit permettre ajout de nouveaux algorithmes de g√©n√©ration (plugins potentiels)
- Interface abstraite pour exporters (faciliter ajout Excel, PDF, etc.)

---

### Logging & Observability

**Framework :** Module `logging` standard Python

**Contraintes :**
- Messages en fran√ßais (NFR10)
- Niveaux : DEBUG, INFO, WARNING, ERROR
- Sortie : console par d√©faut, fichier optionnel via config
- Format : Lisible humain (pas JSON pour MVP)

**Pas de t√©l√©m√©trie, pas de metrics externes** - outil standalone offline.

---

### Security & Code Quality

**Scan de vuln√©rabilit√©s :**
- Dependabot ou √©quivalent activ√© (si GitHub)
- `safety check` dans CI pour d√©pendances

**Code quality gates :**
- Complexity cyclomatique <10 par fonction (ruff config)
- Pas de code dupliqu√© >10 lignes (d√©tection manuelle en code review)

**Pas de secrets** dans le code (pas applicable pour cet outil, mais principe respect√©).

---

### Additional Assumptions

**Reproductibilit√© :**
- Seed al√©atoire configurable pour reproductibilit√© (NFR11)
- R√©sultats d√©terministes √† seed et entr√©es identiques

**Performance baseline :**
- Benchmarks ex√©cut√©s sur machine standard (4 cores, 8GB RAM)
- Pas d'optimisations GPU/CUDA n√©cessaires

**Internationalisation :**
- MVP en fran√ßais uniquement (messages, docs)
- Architecture doit permettre i18n future (mais pas impl√©ment√© MVP)

**Donn√©es de test :**
- G√©n√©rateurs de donn√©es synth√©tiques pour tests
- Pas de donn√©es r√©elles d'√©v√©nements (RGPD, vie priv√©e)

---

## Epic List

### Epic 1: Foundation & Core Algorithm (MVP)
√âtablir l'infrastructure du projet et impl√©menter l'algorithme de g√©n√©ration de planning de base avec m√©triques de qualit√©.

### Epic 2: Optimization & Equity Enforcement (MVP)
Ajouter les phases d'am√©lioration locale et d'enforcement d'√©quit√© pour garantir la qualit√© des plannings selon les contraintes FR4-FR6.

### Epic 3: CLI & Export Capabilities (MVP)
Cr√©er l'interface ligne de commande compl√®te et les fonctionnalit√©s d'export CSV/JSON pour rendre l'outil utilisable en production.

### Epic 4: Edge Cases & Dynamic Management (Post-MVP)
G√©rer les cas limites (tables partielles, configurations impossibles) et permettre la gestion dynamique des participants (retardataires, abandons).

### Epic 5: Visualization & Analysis Tools (Future)
Ajouter des outils de visualisation (notebook Jupyter, heatmaps) et d'analyse avanc√©e pour faciliter l'exploration et la validation des plannings.

---

## Epic 1: Foundation & Core Algorithm

**Epic Goal:**

√âtablir les fondations du projet (configuration, structure, tests) et impl√©menter l'algorithme de g√©n√©ration de planning de base (phase 1 du pipeline). √Ä la fin de cet epic, le syst√®me doit √™tre capable de g√©n√©rer un planning valide pour N participants sur X tables durant S sessions, avec calcul des m√©triques de qualit√©, m√™me si l'optimisation n'est pas encore appliqu√©e. Cet epic pose les bases pour tous les d√©veloppements futurs en cr√©ant une architecture propre, testable et document√©e.

### Story 1.1: Setup Initial du Projet

As a d√©veloppeur,
I want un projet Python correctement structur√© avec toutes les configurations de base,
so that je peux commencer √† d√©velopper le syst√®me dans un environnement propre et reproductible.

**Acceptance Criteria:**

1. Le repository Git est initialis√© avec structure de dossiers standard (`src/`, `tests/`, `docs/`, `examples/`)
2. Le fichier `pyproject.toml` (Poetry) ou `setup.py` est configur√© avec m√©tadonn√©es du projet (nom, version 0.1.0, auteur, description, Python >=3.10)
3. Le fichier `.gitignore` exclut les fichiers Python standards (`__pycache__`, `.pytest_cache`, `*.pyc`, `.venv`, etc.)
4. Les d√©pendances dev sont install√©es et fonctionnelles : `pytest`, `pytest-cov`, `black`, `ruff`, `mypy`
5. Un fichier `README.md` de base existe avec titre du projet et description d'une phrase
6. La commande `pytest` s'ex√©cute sans erreur (m√™me sans tests encore)
7. La commande `black .` et `ruff check .` s'ex√©cutent sans erreur sur le code existant
8. Un fichier `.pre-commit-config.yaml` est configur√© avec hooks pour black, ruff, mypy

### Story 1.2: D√©finir les Structures de Donn√©es Fondamentales

As a d√©veloppeur,
I want des dataclasses Python typ√©es repr√©sentant les entit√©s du domaine,
so that je peux manipuler les plannings, sessions, et configurations de mani√®re type-safe et testable.

**Acceptance Criteria:**

1. Un module `src/models.py` contient une dataclass `Planning` repr√©sentant une liste de sessions
2. Une dataclass `Session` repr√©sente une liste de tables pour une session donn√©e
3. Une dataclass `Table` (ou type alias `Set[int]`) repr√©sente un ensemble de participant IDs
4. Une dataclass `PlanningConfig` contient les param√®tres d'entr√©e : N, X, x, S avec validation dans `__post_init__`
5. Une dataclass `PlanningMetrics` contient toutes les m√©triques de qualit√© d√©finies dans FR8-FR9
6. Tous les types sont document√©s avec docstrings Google style
7. Les tests unitaires dans `tests/test_models.py` valident :
   - La cr√©ation valide d'un `PlanningConfig` avec param√®tres corrects
   - Le rejet avec exception pour param√®tres invalides (N‚â§0, X√óx<N, etc.) selon FR2
   - L'immutabilit√© ou mutabilit√© contr√¥l√©e des structures
8. `mypy src/models.py` passe sans erreur avec mode strict

### Story 1.3: Impl√©menter la Validation des Param√®tres d'Entr√©e

As a organisateur d'√©v√©nement,
I want que le syst√®me valide mes param√®tres d'entr√©e et me donne des messages d'erreur clairs en fran√ßais,
so that je sais imm√©diatement si ma configuration est viable avant de lancer la g√©n√©ration.

**Acceptance Criteria:**

1. Un module `src/validation.py` contient une fonction `validate_config(config: PlanningConfig) -> None` qui lance des exceptions typ√©es
2. La validation v√©rifie toutes les contraintes FR1-FR2 :
   - N ‚â• 2, X ‚â• 1, x ‚â• 2, S ‚â• 1
   - X √ó x ‚â• N (capacit√© suffisante)
3. Les exceptions personnalis√©es (`InvalidConfigurationError`) ont des messages en fran√ßais explicites conformes √† NFR10
4. Exemples de messages : "Nombre de participants invalide : N=0. Minimum requis : 2", "Capacit√© insuffisante : 5 tables √ó 4 places = 20 < 25 participants"
5. Les tests dans `tests/test_validation.py` couvrent tous les cas d'erreur avec v√©rification des messages fran√ßais
6. Les tests v√©rifient qu'une configuration valide ne l√®ve pas d'exception
7. La couverture de tests du module `validation.py` est ‚â•95%

### Story 1.4: Impl√©menter l'Algorithme de G√©n√©ration Baseline (Round-Robin)

As a d√©veloppeur,
I want un algorithme de g√©n√©ration rapide produisant un planning valide initial,
so that le syst√®me peut toujours fournir un r√©sultat m√™me sans optimisation avanc√©e.

**Acceptance Criteria:**

1. Un module `src/baseline.py` contient une fonction `generate_baseline(config: PlanningConfig, seed: int = 42) -> Planning`
2. L'algorithme impl√©mente une strat√©gie de rotation syst√©matique (round-robin g√©n√©ralis√© avec stride)
3. Pour chaque session, tous les N participants sont assign√©s √† exactement une table
4. La fonction garantit que chaque table respecte la contrainte de capacit√© x
5. La gestion des tables partielles est correcte : si N n'est pas multiple de x, les participants sont r√©partis avec √©cart de taille ‚â§1 entre tables (FR7)
6. L'algorithme est d√©terministe : √† seed identique, g√©n√®re le m√™me planning (NFR11)
7. Les tests dans `tests/test_baseline.py` v√©rifient :
   - Planning valide pour config simple (N=30, X=5, x=6, S=6)
   - Planning valide pour tables partielles (N=37, X=6, x=7)
   - D√©terminisme (2 appels avec m√™me seed = m√™me r√©sultat)
   - Performance : g√©n√©ration pour N=100 en <1s
8. Aucun participant n'est oubli√© ou dupliqu√© dans une session

### Story 1.5: Impl√©menter le Calcul de l'Historique des Rencontres

As a d√©veloppeur,
I want une fonction calculant quels participants se sont d√©j√† rencontr√©s,
so that je peux mesurer les r√©p√©titions et pr√©parer les phases d'optimisation futures.

**Acceptance Criteria:**

1. Un module `src/metrics.py` contient une fonction `compute_meeting_history(planning: Planning) -> Set[Tuple[int, int]]`
2. La fonction retourne l'ensemble de toutes les paires de participants qui se sont rencontr√©s au moins une fois
3. Les paires sont normalis√©es : `(min(i,j), max(i,j))` pour √©viter duplications `(i,j)` et `(j,i)`
4. La complexit√© est O(S √ó X √ó x¬≤) dans le pire cas
5. Les tests dans `tests/test_metrics.py` v√©rifient :
   - Planning sans r√©p√©titions : `len(met_pairs)` = nombre de paires attendu
   - Planning avec r√©p√©titions connues : paires d√©tect√©es correctement
   - Normalisation des paires : `(0,1)` pr√©sent, pas `(1,0)`
6. La fonction g√®re correctement les tables de tailles variables

### Story 1.6: Impl√©menter le Calcul des M√©triques de Qualit√©

As a organisateur d'√©v√©nement,
I want des m√©triques pr√©cises sur la qualit√© de mon planning,
so that je peux √©valuer si le planning g√©n√©r√© r√©pond √† mes besoins d'√©quit√© et de diversit√©.

**Acceptance Criteria:**

1. Une fonction `compute_metrics(planning: Planning, config: PlanningConfig) -> PlanningMetrics` dans `src/metrics.py` calcule toutes les m√©triques FR8-FR9
2. Les m√©triques calcul√©es incluent :
   - `total_unique_pairs`: nombre total de paires uniques rencontr√©es
   - `total_repeat_pairs`: nombre de paires rencontr√©es plus d'une fois
   - `unique_meetings_per_person`: liste de taille N avec rencontres uniques par participant
   - `min_unique`, `max_unique`, `mean_unique`, `std_unique`: statistiques d'√©quit√©
   - `table_sizes_per_session`: distribution des tailles de tables par session
3. La fonction calcule correctement l'√©cart max-min pour v√©rifier FR6 (√©quit√© ¬±1)
4. Les tests v√©rifient le calcul sur des plannings construits manuellement avec r√©sultats attendus connus
5. Les tests v√©rifient que pour un planning "parfait" (z√©ro r√©p√©tition), `total_repeat_pairs == 0`
6. La performance est acceptable : calcul en <100ms pour N=300, S=20
7. La couverture de tests du module `metrics.py` est ‚â•90%

### Story 1.7: Tests d'Int√©gration Pipeline Baseline Complet

As a d√©veloppeur,
I want des tests d'int√©gration validant le pipeline complet de g√©n√©ration baseline + m√©triques,
so that je garantis que toutes les pi√®ces fonctionnent ensemble correctement.

**Acceptance Criteria:**

1. Un fichier `tests/test_integration_baseline.py` contient des tests end-to-end
2. Test "Exemple A" (N=30, X=5, x=6, S=6) :
   - Validation config passe
   - G√©n√©ration baseline produit planning valide
   - M√©triques calcul√©es sans erreur
   - V√©rification : tous les participants pr√©sents chaque session, tables √©quilibr√©es
3. Test "Exemple B" (N=100, X=20, x=5, S=10) :
   - Pipeline complet r√©ussit
   - Performance : <2s total (NFR1)
4. Test "Tables partielles" (N=37, X=6, x=7) :
   - Planning g√©n√©r√© avec gestion correcte du remainder
   - √âcart de taille ‚â§1 v√©rifi√© dans m√©triques
5. Test "Configuration invalide" :
   - X √ó x < N ‚Üí exception lev√©e avec message fran√ßais
6. Tous les tests d'int√©gration passent et la suite s'ex√©cute en <5s

### Story 1.8: Documentation et Exemples de Base

As a d√©veloppeur futur,
I want une documentation claire du code et des exemples d'utilisation,
so that je comprends rapidement comment fonctionne le syst√®me et comment l'√©tendre.

**Acceptance Criteria:**

1. Toutes les fonctions publiques ont des docstrings Google style avec :
   - Description br√®ve
   - Args avec types
   - Returns avec type
   - Raises (exceptions possibles)
   - Exemple d'utilisation si pertinent
2. Le `README.md` est mis √† jour avec :
   - Description du projet (2-3 paragraphes)
   - Installation (`pip install -e .`)
   - Exemple d'utilisation Python basique (5-10 lignes de code)
   - Structure du projet (arborescence)
3. Un fichier `examples/basic_usage.py` d√©montre :
   - Cr√©ation d'un `PlanningConfig`
   - G√©n√©ration baseline
   - Calcul et affichage des m√©triques
4. Le code de l'exemple s'ex√©cute sans erreur
5. Un fichier `docs/architecture.md` d√©crit l'architecture 3 phases (m√™me si seule phase 1 impl√©ment√©e)

---

## Epic 2: Optimization & Equity Enforcement

**Epic Goal:**

Impl√©menter les phases 2 et 3 du pipeline hybride pour transformer les plannings baseline en plannings de haute qualit√© respectant les contraintes d'optimisation (FR4-FR5) et d'√©quit√© stricte (FR6). √Ä la fin de cet epic, le syst√®me doit produire des plannings minimisant les r√©p√©titions tout en garantissant que chaque participant rencontre un nombre similaire de personnes uniques (√©cart ‚â§1). Cet epic apporte la valeur diff√©renciatrice du syst√®me par rapport aux approches na√Øves.

### Story 2.1: Impl√©menter l'√âvaluation de Qualit√© d'un Swap

As a d√©veloppeur,
I want une fonction √©valuant si √©changer deux participants entre tables am√©liore la qualit√© du planning,
so that je peux construire l'heuristique d'am√©lioration locale sur cette primitive.

**Acceptance Criteria:**

1. Un module `src/optimizer.py` contient une fonction `evaluate_swap(planning, session_id, table1_id, p1, table2_id, p2, met_pairs) -> int`
2. La fonction calcule le delta de r√©p√©titions avant/apr√®s swap (n√©gatif = am√©lioration)
3. Le calcul compare combien de paires r√©p√©t√©es existent avec p1 dans table1 et p2 dans table2 vs apr√®s swap
4. La fonction ne modifie PAS le planning (√©valuation pure)
5. Les tests dans `tests/test_optimizer.py` v√©rifient :
   - Swap b√©n√©fique d√©tect√© correctement (delta < 0)
   - Swap neutre d√©tect√© (delta == 0)
   - Swap n√©faste d√©tect√© (delta > 0)
   - Performance : √©valuation en <1ms pour tables de taille 10
6. La fonction g√®re correctement les cas o√π p1 ou p2 n'ont aucune rencontre pr√©alable

### Story 2.2: Impl√©menter l'Am√©lioration Locale par Swaps Gloutons

As a organisateur d'√©v√©nement,
I want que le syst√®me am√©liore automatiquement la qualit√© du planning baseline,
so that je re√ßois un planning avec le minimum de r√©p√©titions possible.

**Acceptance Criteria:**

1. Une fonction `improve_planning(planning: Planning, config: PlanningConfig, max_iterations: int = 100) -> Planning` dans `src/optimizer.py`
2. L'algorithme it√®re sur toutes les sessions et teste des swaps entre tables
3. √Ä chaque it√©ration, si un swap am√©liore le score (r√©duit r√©p√©titions), il est appliqu√©
4. L'algorithme s'arr√™te quand aucune am√©lioration n'est trouv√©e (plateau local) ou max_iterations atteint
5. Un syst√®me de logging (niveau INFO) indique : "It√©ration X: Y swaps appliqu√©s, Z r√©p√©titions √©limin√©es"
6. Les tests v√©rifient :
   - Planning avec r√©p√©titions connues ‚Üí am√©lioration mesurable apr√®s `improve_planning`
   - D√©tection du plateau local (stop avant max_iterations si plus d'am√©liorations)
   - D√©terminisme (seed fixe ‚Üí m√™me r√©sultat)
   - Performance : am√©lioration pour N=100, S=10 en <3s
7. Le planning retourn√© est toujours valide (tous participants assign√©s, contraintes respect√©es)

### Story 2.3: Impl√©menter l'Enforcement de l'√âquit√© Stricte

As a organisateur d'√©v√©nement,
I want que tous les participants aient une exp√©rience √©quitable avec un √©cart de rencontres uniques ‚â§1,
so that personne ne se sente d√©savantag√© lors de l'√©v√©nement.

**Acceptance Criteria:**

1. Une fonction `enforce_equity(planning: Planning, config: PlanningConfig) -> Planning` dans `src/optimizer.py`
2. La fonction calcule les rencontres uniques par participant via `compute_metrics`
3. Si `max_unique - min_unique <= 1`, le planning est retourn√© inchang√©
4. Sinon, la fonction identifie participants sur-expos√©s (> moyenne) et sous-expos√©s (< moyenne)
5. Des swaps cibl√©s sont effectu√©s pour r√©duire l'√©cart tout en minimisant l'impact sur les r√©p√©titions
6. La fonction garantit que le planning final respecte FR6 (√©quit√© ¬±1)
7. Les tests v√©rifient :
   - Planning d√©j√† √©quitable ‚Üí inchang√©
   - Planning d√©s√©quilibr√© (√©cart 3) ‚Üí ramen√© √† √©cart ‚â§1
   - M√©triques finales confirment `max_unique - min_unique <= 1`
   - Performance : enforcement pour N=300 en <2s
8. Un message de logging INFO indique : "√âquit√© atteinte : √©cart de X rencontres entre min et max"

### Story 2.4: Impl√©menter le Pipeline Complet d'Optimisation

As a d√©veloppeur,
I want une fonction orchestrant les 3 phases du pipeline hybride,
so that je peux g√©n√©rer des plannings optimis√©s en un seul appel de fonction.

**Acceptance Criteria:**

1. Un module `src/planner.py` contient une fonction `generate_optimized_planning(config: PlanningConfig, seed: int = 42) -> Tuple[Planning, PlanningMetrics]`
2. La fonction ex√©cute s√©quentiellement :
   - Phase 1 : `generate_baseline(config, seed)`
   - Phase 2 : `improve_planning(baseline, config)`
   - Phase 3 : `enforce_equity(improved, config)`
   - Calcul final : `compute_metrics(final_planning, config)`
3. Chaque phase logue son ex√©cution (niveau INFO) : "Phase 1: Baseline g√©n√©r√©e", "Phase 2: X r√©p√©titions √©limin√©es", "Phase 3: √âquit√© garantie"
4. La fonction retourne le planning final ET ses m√©triques
5. Les tests v√©rifient :
   - Pipeline complet pour config standard (N=30) r√©ussit
   - M√©triques finales confirment FR6 (√©quit√© ¬±1)
   - Planning final est valide (aucun participant oubli√©)
6. La fonction g√®re les configurations impossibles (S √ó (x-1) < N-1) en loguant un WARNING mais produit quand m√™me le meilleur planning possible

### Story 2.5: Tests de Performance et Benchmarks

As a d√©veloppeur,
I want des benchmarks syst√©matiques validant les contraintes de performance NFR1-NFR3,
so that je garantis que le syst√®me reste utilisable en production pour toutes les tailles d'√©v√©nements.

**Acceptance Criteria:**

1. Un fichier `tests/test_performance.py` contient des benchmarks pour les 3 niveaux de performance
2. Benchmark NFR1 (N=100, X=20, x=5, S=10) :
   - Pipeline complet s'ex√©cute en <2s
   - R√©sultat enregistr√© dans fichier JSON (`benchmarks/results.json`)
3. Benchmark NFR2 (N=300, X=60, x=5, S=15) :
   - Pipeline complet s'ex√©cute en <5s
4. Benchmark NFR3 (N=1000, X=200, x=5, S=25) :
   - Pipeline complet s'ex√©cute en <30s
5. Les benchmarks mesurent aussi l'empreinte m√©moire (v√©rification NFR4 : <O(N¬≤))
6. Un script `scripts/run_benchmarks.py` ex√©cute tous les benchmarks et g√©n√®re un rapport format√©
7. Les tests de performance sont marqu√©s `@pytest.mark.slow` et exclus des tests rapides par d√©faut
8. Le CI ex√©cute les benchmarks sur chaque merge √† `main` et d√©tecte les r√©gressions (>10% ralentissement)

### Story 2.6: Tests d'Int√©gration Pipeline Complet Optimis√©

As a d√©veloppeur,
I want des tests d'int√©gration validant que le pipeline complet (3 phases) produit des plannings de haute qualit√©,
so that je garantis la valeur livr√©e aux utilisateurs finaux.

**Acceptance Criteria:**

1. Un fichier `tests/test_integration_optimized.py` contient des tests end-to-end du pipeline complet
2. Test "Exemple A optimis√©" (N=30, X=5, x=6, S=6) :
   - Pipeline 3 phases ex√©cut√©
   - M√©triques finales : √©quit√© ¬±1 v√©rifi√©e, r√©p√©titions minimales (<5% du total)
   - Comparaison avant/apr√®s : am√©lioration locale r√©duit r√©p√©titions d'au moins 50% vs baseline
3. Test "Configuration impossible" (N=32, S=3, X=4, x=8) :
   - D√©tection math√©matique : S √ó (x-1) = 21 < N-1 = 31
   - WARNING logg√© indiquant impossibilit√©
   - Planning g√©n√©r√© quand m√™me avec r√©p√©titions √©quitablement r√©parties
   - √âquit√© ¬±1 toujours respect√©e
4. Test "Grande instance" (N=300) :
   - Pipeline complet r√©ussit
   - Performance <5s (NFR2)
   - √âquit√© ¬±1 garantie
5. Tous les tests d'int√©gration passent avec couverture ‚â•85%

### Story 2.7: Documentation de l'Optimisation

As a utilisateur technique,
I want une documentation expliquant comment fonctionne l'optimisation et comment interpr√©ter les m√©triques,
so that je comprends la valeur ajout√©e du syst√®me et comment configurer les param√®tres avanc√©s.

**Acceptance Criteria:**

1. Le fichier `docs/architecture.md` est compl√©t√© avec :
   - Description d√©taill√©e des 3 phases du pipeline
   - Explication de l'heuristique de swaps gloutons
   - Crit√®res d'arr√™t (plateau local, max_iterations)
   - Trade-offs √©quit√© vs r√©p√©titions minimales
2. Le `README.md` inclut une section "Comment √ßa marche ?" avec :
   - Sch√©ma textuel du pipeline 3 phases
   - Exemple de m√©triques avant/apr√®s optimisation
3. Un fichier `examples/advanced_usage.py` d√©montre :
   - Utilisation de `generate_optimized_planning`
   - Affichage des m√©triques d√©taill√©es
   - Comparaison baseline vs optimis√©
4. Le code de l'exemple s'ex√©cute sans erreur et produit une sortie lisible
5. Les docstrings des fonctions d'optimisation expliquent la complexit√© algorithmique et les garanties

---

## Epic 3: CLI & Export Capabilities

**Epic Goal:**

Cr√©er l'interface utilisateur compl√®te (CLI) et les fonctionnalit√©s d'export permettant aux organisateurs d'√©v√©nements d'utiliser le syst√®me en production. √Ä la fin de cet epic, l'outil est livrable : un utilisateur peut installer le package, ex√©cuter une commande avec ses param√®tres, obtenir un planning optimis√©, et l'exporter aux formats CSV/JSON pour int√©gration avec ses syst√®mes √©v√©nementiels. Cet epic finalise le MVP en transformant une biblioth√®que algorithmique en produit utilisable.

### Story 3.1: Impl√©menter l'Exporteur CSV

As a organisateur d'√©v√©nement,
I want exporter mon planning au format CSV,
so that je peux l'importer dans Excel, Google Sheets ou mon syst√®me de gestion d'√©v√©nements.

**Acceptance Criteria:**

1. Un module `src/exporters.py` contient une fonction `export_to_csv(planning: Planning, config: PlanningConfig, filepath: str) -> None`
2. Le fichier CSV g√©n√©r√© contient exactement les colonnes : `session_id`, `table_id`, `participant_id` (FR10)
3. Les IDs sont des entiers (0-indexed pour participants, 0-indexed pour sessions, 0-indexed pour tables)
4. Le fichier est encod√© en UTF-8 avec BOM pour compatibilit√© Excel
5. Les tests dans `tests/test_exporters.py` v√©rifient :
   - Export r√©ussit sans erreur pour planning valide
   - Fichier CSV produit contient bon nombre de lignes (N √ó S)
   - Lecture du CSV avec `csv.DictReader` fonctionne
   - Valeurs correctes pour un planning connu
6. La fonction g√®re correctement les chemins avec espaces et caract√®res sp√©ciaux
7. Si le fichier existe d√©j√†, il est √©cras√© (avec warning logg√©)

### Story 3.2: Impl√©menter l'Exporteur JSON

As a organisateur d'√©v√©nement,
I want exporter mon planning au format JSON structur√©,
so that je peux l'utiliser dans des applications web ou API sans parsing complexe.

**Acceptance Criteria:**

1. Une fonction `export_to_json(planning: Planning, config: PlanningConfig, filepath: str) -> None` dans `src/exporters.py`
2. Le fichier JSON suit la structure exacte sp√©cifi√©e dans FR11 : `{"sessions": [{"session_id": int, "tables": [{"table_id": int, "participants": [int]}]}]}`
3. Le JSON est indent√© (2 espaces) pour lisibilit√© humaine
4. Le fichier est encod√© en UTF-8
5. Les tests v√©rifient :
   - Export r√©ussit sans erreur
   - JSON produit est valide (parsing avec `json.load` r√©ussit)
   - Structure conforme √† FR11
   - Valeurs correctes pour un planning connu
6. Un champ optionnel `metadata` peut √™tre ajout√© avec : `{"config": {"N": ..., "X": ..., "x": ..., "S": ...}, "metrics": {...}}`
7. Si filepath non fourni, la fonction retourne le JSON sous forme de string

### Story 3.3: Impl√©menter le Parseur d'Arguments CLI

As a utilisateur,
I want une interface en ligne de commande intuitive avec des arguments clairs,
so that je peux facilement g√©n√©rer des plannings sans √©crire de code Python.

**Acceptance Criteria:**

1. Un module `src/cli.py` contient une fonction `parse_args()` utilisant `argparse`
2. Les arguments obligatoires (NFR7) sont support√©s :
   - `--participants N` ou `-n N`
   - `--tables X` ou `-t X`
   - `--capacity x` ou `-c x`
   - `--sessions S` ou `-s S`
3. Les arguments optionnels sont support√©s :
   - `--output fichier` ou `-o fichier` (d√©faut : `planning.csv`)
   - `--format {csv|json}` ou `-f {csv|json}` (d√©faut : `csv`)
   - `--seed SEED` (d√©faut : `42`)
   - `--verbose` ou `-v` (active logging DEBUG)
   - `--config fichier` (fichier YAML/JSON de configuration, non impl√©ment√© dans MVP mais pr√©par√©)
4. L'aide (`--help`) affiche une description claire en fran√ßais de chaque argument
5. Les tests dans `tests/test_cli.py` v√©rifient :
   - Parsing r√©ussit avec arguments minimaux
   - Parsing r√©ussit avec tous les arguments
   - Parsing √©choue avec message clair si argument obligatoire manquant
   - Valeurs par d√©faut correctes
6. Les descriptions d'aide sont en fran√ßais (NFR10)

### Story 3.4: Impl√©menter la Fonction Main de la CLI

As a utilisateur,
I want ex√©cuter une seule commande pour g√©n√©rer et exporter un planning complet,
so that je peux utiliser l'outil sans connaissance Python approfondie.

**Acceptance Criteria:**

1. Une fonction `main()` dans `src/cli.py` orchestre le flux CLI complet
2. Le flux ex√©cut√© est :
   - Parsing des arguments
   - Configuration du logging (INFO par d√©faut, DEBUG si `--verbose`)
   - Cr√©ation de `PlanningConfig` depuis les arguments
   - Appel de `generate_optimized_planning(config, seed)`
   - Affichage console des m√©triques cl√©s (paires uniques, r√©p√©titions, √©quit√©)
   - Export vers fichier selon `--format` et `--output`
   - Message de succ√®s : "Planning g√©n√©r√© avec succ√®s : X paires uniques, Y r√©p√©titions, √©quit√© ¬±Z. Export√© vers {fichier}"
3. Gestion d'erreurs robuste avec messages en fran√ßais (NFR10) :
   - Configuration invalide ‚Üí affichage du message d'erreur de validation et exit code 1
   - Erreur I/O (export impossible) ‚Üí message clair et exit code 2
   - Erreur inattendue ‚Üí stack trace si `--verbose`, sinon message g√©n√©rique et exit code 3
4. Les tests v√©rifient :
   - Ex√©cution r√©ussie end-to-end avec arguments valides
   - Exit code 0 sur succ√®s
   - Exit code != 0 sur erreur
   - Fichier de sortie cr√©√© et valide
5. La fonction retourne l'exit code (pour testabilit√©)

### Story 3.5: Cr√©er le Point d'Entr√©e Ex√©cutable

As a utilisateur,
I want installer le package et ex√©cuter une commande globale dans mon terminal,
so that je n'ai pas besoin d'appeler Python directement avec des chemins de modules.

**Acceptance Criteria:**

1. Le `pyproject.toml` (ou `setup.py`) d√©finit un entry point console : `speed-dating-planner = src.cli:main`
2. Apr√®s installation (`pip install -e .`), la commande `speed-dating-planner` est disponible globalement
3. L'ex√©cution de `speed-dating-planner --help` affiche l'aide compl√®te
4. L'ex√©cution de `speed-dating-planner -n 30 -t 5 -c 6 -s 6 -o test.csv` g√©n√®re un planning et l'exporte
5. Les tests dans `tests/test_cli_integration.py` v√©rifient :
   - Commande ex√©cutable trouv√©e apr√®s installation
   - Ex√©cution via subprocess r√©ussit
   - Fichier de sortie cr√©√© avec contenu valide
6. Un alias court `sdp` peut √™tre ajout√© (optionnel)

### Story 3.6: Affichage Console des M√©triques

As a utilisateur,
I want voir les r√©sultats de g√©n√©ration directement dans le terminal,
so that je peux √©valuer la qualit√© du planning avant de consulter le fichier export√©.

**Acceptance Criteria:**

1. La fonction `main()` affiche un r√©sum√© format√© des m√©triques apr√®s g√©n√©ration
2. Le format d'affichage console inclut : participants, sessions, tables, paires uniques cr√©√©es, r√©p√©titions, statistiques d'√©quit√© (min, max, moyenne, √©cart)
3. Les √©mojis sont optionnels (activ√©s seulement si terminal supporte UTF-8)
4. En mode `--verbose`, affichage additionnel : temps d'ex√©cution par phase, nombre d'it√©rations d'am√©lioration
5. Les tests v√©rifient :
   - Sortie console contient les m√©triques cl√©s
   - Format lisible (pas de dump JSON brut)
6. Si configuration impossible d√©tect√©e, un warning clair est affich√© avant les m√©triques

### Story 3.7: Tests d'Int√©gration CLI End-to-End

As a d√©veloppeur,
I want des tests complets validant le flux CLI de bout en bout,
so that je garantis que l'outil est utilisable en production par des non-d√©veloppeurs.

**Acceptance Criteria:**

1. Un fichier `tests/test_cli_e2e.py` contient des tests end-to-end via subprocess
2. Test "G√©n√©ration CSV simple" :
   - Ex√©cution : `speed-dating-planner -n 30 -t 5 -c 6 -s 6 -o output.csv`
   - Exit code 0
   - Fichier `output.csv` cr√©√© avec 180 lignes (30√ó6)
   - Contenu CSV valide et conforme FR10
3. Test "G√©n√©ration JSON avec seed" :
   - Ex√©cution : `speed-dating-planner -n 100 -t 20 -c 5 -s 10 --format json --seed 42 -o output.json`
   - Exit code 0
   - JSON valide et conforme FR11
   - Reproductibilit√© : 2 ex√©cutions avec m√™me seed ‚Üí m√™me JSON
4. Test "Configuration invalide" :
   - Ex√©cution : `speed-dating-planner -n 50 -t 5 -c 8 -s 3` (capacit√© insuffisante)
   - Exit code 1
   - Message d'erreur en fran√ßais affich√©
5. Test "Mode verbose" :
   - Ex√©cution avec `--verbose`
   - Logs DEBUG visibles dans sortie
6. Tous les tests e2e passent et nettoient les fichiers g√©n√©r√©s (cleanup dans teardown)

### Story 3.8: Documentation Utilisateur Compl√®te

As a organisateur d'√©v√©nement,
I want une documentation claire m'expliquant comment installer et utiliser l'outil,
so that je peux g√©n√©rer mes plannings sans assistance technique.

**Acceptance Criteria:**

1. Le `README.md` contient une section "Installation" avec :
   - Pr√©requis (Python 3.10+)
   - Commandes d'installation (`pip install -e .` pour dev, ou `pip install speed-dating-planner` si publi√©)
   - V√©rification de l'installation (`speed-dating-planner --help`)
2. Une section "Utilisation" avec :
   - Exemple basique avec param√®tres minimaux
   - Exemple avanc√© avec tous les arguments
   - Explication de chaque param√®tre
   - Interpr√©tation des m√©triques affich√©es
3. Une section "Exemples Concrets" (NFR12) :
   - Petit √©v√©nement (N=30)
   - Moyen √©v√©nement (N=100)
   - Grand √©v√©nement (N=300)
   - Pour chacun : commande compl√®te + r√©sultats attendus
4. Une section "Troubleshooting" avec :
   - Configuration invalide ‚Üí que faire
   - Performance lente ‚Üí attentes r√©alistes
   - R√©p√©titions in√©vitables ‚Üí explication math√©matique
5. Le fichier `examples/cli_usage.sh` contient des exemples shell ex√©cutables
6. Un fichier `docs/user-guide.md` approfondit l'utilisation avec captures d'√©cran simul√©es (texte)

---

## Checklist Results Report

### PM Checklist Validation - Executive Summary

**PRD Completeness:** 92%
**MVP Scope Appropriateness:** Just Right ‚úì
**Readiness for Architecture Phase:** **READY** ‚úì

### Category Statuses

| Category                         | Status | Critical Issues                                      |
| -------------------------------- | ------ | ---------------------------------------------------- |
| 1. Problem Definition & Context  | PASS   | Aucun (personas implicites mais clairs)              |
| 2. MVP Scope Definition          | PASS   | Aucun (s√©paration MVP/post-MVP exemplaire)           |
| 3. User Experience Requirements  | PASS   | Aucun (CLI-first appropri√©)                          |
| 4. Functional Requirements       | PASS   | Aucun (FR1-FR16 testables, priorit√©s claires)       |
| 5. Non-Functional Requirements   | PASS   | Aucun (NFR1-NFR12 complets)                          |
| 6. Epic & Story Structure        | PASS   | Aucun (Epic 1-3 MVP d√©taill√©s)                       |
| 7. Technical Guidance            | PASS   | Aucun (Technical Assumptions exceptionnelles)        |
| 8. Cross-Functional Requirements | PASS   | Aucun (appropri√© pour outil CLI standalone)         |
| 9. Clarity & Communication       | PASS   | Aucun (document structur√©, en fran√ßais)              |

### Critical Deficiencies

**BLOCKERS:** Aucun

**Areas for Improvement (Non-Blocking):**
- Success metrics business quantifi√©s (adoption, satisfaction)
- User personas formalis√©s
- Competitive analysis

### Recommendations

‚úÖ **PRD est READY FOR ARCHITECT**

**Next Steps:**
1. Passer ce PRD √† l'Architect agent pour cr√©ation de `docs/architecture.md`
2. L'Architect d√©finira structure modules, patterns, interfaces pipeline, strat√©gies testing
3. Validation architecture ‚Üí Scrum Master pour cr√©ation stories d√©taill√©es
4. Dev agent pour impl√©mentation Epic par Epic

### Final Decision

**READY FOR ARCHITECT** - Le PRD est exceptionnellement complet (92/100), bien structur√©, et pr√™t pour la phase de design architectural.

---

## Epic 4: Edge Cases & Dynamic Management (Post-MVP)

**Epic Goal:** G√©rer les cas limites et permettre la gestion dynamique des participants (retardataires, abandons) avec recalcul partiel du planning.

**Stories (High-Level):**
- D√©tection et signalement des configurations math√©matiquement impossibles (FR12)
- G√©n√©ration du meilleur planning possible pour configurations impossibles (FR13)
- Gestion de l'ajout dynamique de participants retardataires (FR14)
- Gestion des abandons de participants (FR15)
- Tests robustesse sur cas limites vari√©s

---

## Epic 5: Visualization & Analysis Tools (Future)

**Epic Goal:** Ajouter des outils de visualisation et d'analyse avanc√©e pour faciliter l'exploration et la validation des plannings.

**Stories (High-Level):**
- Cr√©ation de notebook Jupyter interactif avec exemples
- G√©n√©ration de heatmap des rencontres (matplotlib)
- Visualisation des m√©triques d'√©quit√© par session
- Outils de comparaison entre diff√©rents plannings
- Export vers formats additionnels (Excel, PDF)

---

## Next Steps

### UX Expert Prompt

**Note:** Ce projet est principalement un outil CLI algorithmique sans interface graphique complexe. L'UX Expert peut √™tre **optionnel** pour ce MVP.

Si consultation UX souhait√©e, utiliser ce prompt :

```
Analyser le PRD du syst√®me d'optimisation de tables rotatives (docs/prd.md) et valider que l'exp√©rience CLI propos√©e est optimale pour les organisateurs d'√©v√©nements.

Focus areas:
- Est-ce que l'interface CLI (arguments, flags) est intuitive ?
- Le format d'affichage des m√©triques console est-il clair et actionnable ?
- Les messages d'erreur en fran√ßais sont-ils suffisamment explicites ?
- Y a-t-il des opportunit√©s pour am√©liorer l'UX sans ajouter de complexit√© ?

Livrable: Recommandations UX pour am√©liorer la clart√© et l'utilisabilit√© de la CLI (optionnel).
```

### Architect Prompt

```
Cr√©er le document d'architecture technique complet pour le syst√®me d'optimisation de tables rotatives bas√© sur le PRD (docs/prd.md) et la session de brainstorming (docs/brainstorming-session-results.md).

Contexte:
- Outil CLI Python 3.10+ pour g√©n√©ration de plannings de networking/speed dating
- Architecture hybride 3 phases obligatoire : Baseline ‚Üí Am√©lioration ‚Üí √âquit√©
- MVP = Epic 1-3 (Foundation + Optimization + CLI & Export)
- Contraintes: stdlib Python uniquement pour MVP, performance N‚â§1000 en <30s, √©quit√© ¬±1 garantie

Livrables requis dans docs/architecture.md:
1. Vue d'ensemble de l'architecture (sch√©ma ASCII des 3 phases + flux de donn√©es)
2. Structure d√©taill√©e des modules Python avec responsabilit√©s
3. D√©finition des interfaces entre modules (signatures fonctions cl√©s)
4. Mod√®les de donn√©es (dataclasses exactes : Planning, Metrics, Config)
5. Strat√©gie de testing (unitaires, int√©gration, performance)
6. D√©cisions techniques justifi√©es (structures de donn√©es, patterns, algorithmes)
7. Gestion des erreurs et logging
8. Consid√©rations de performance et scalabilit√©
9. Plan de migration/extension pour Epic 4-5 post-MVP

Contraintes importantes:
- Respecter les Technical Assumptions du PRD (Poetry, black/ruff/mypy, pytest, GitHub Actions)
- Architecture modulaire testable ind√©pendamment (NFR9)
- HashMap pour historique rencontres (pas matrice N√óN)
- Reproductibilit√© via seed (NFR11)
- Messages d'erreur en fran√ßais (NFR10)

Cr√©er une architecture propre, pragmatique et impl√©mentable qui guide le d√©veloppement des Epic 1-3 MVP.
```

---

**üéâ PRD COMPLET ET VALID√â - READY FOR NEXT PHASE**

Ce PRD a √©t√© cr√©√© par l'agent Product Manager (John) bas√© sur la session de brainstorming du 2026-01-10 avec l'agent Business Analyst (Mary).

**Document Version:** 1.0
**Status:** ‚úÖ Ready for Architecture Phase
**Next Agent:** Architect

---
