# Story 1.8: Documentation et Exemples de Base

## Status

**Draft**

---

## Story

**As a** développeur futur,
**I want** une documentation claire du code et des exemples d'utilisation,
**so that** je comprends rapidement comment fonctionne le système et comment l'étendre.

---

## Acceptance Criteria

1. Toutes les fonctions publiques ont des docstrings Google style avec :
   - Description brève
   - Args avec types
   - Returns avec type
   - Raises (exceptions possibles)
   - Exemple d'utilisation si pertinent
2. Le `README.md` est mis à jour avec :
   - Description du projet (2-3 paragraphes)
   - Installation (`pip install -e .`)
   - Exemple d'utilisation Python basique (5-10 lignes de code)
   - Structure du projet (arborescence)
   - Liens vers architecture shardée (`docs/architecture/index.md`)
   - Mention CLI à venir (Epic 3)
3. Un fichier `examples/basic_usage.py` démontre :
   - Création d'un `PlanningConfig`
   - Génération baseline
   - Calcul et affichage des métriques
4. Le code de l'exemple s'exécute sans erreur
5. Un fichier `examples/README.md` explique les exemples disponibles
6. Le QA gate YAML vérifie que l'exemple s'exécute correctement

---

## Tasks / Subtasks

- [ ] **Task 1: Vérifier et compléter docstrings des modules** (AC: 1)
  - [ ] `src/models.py`: Docstrings Google style pour PlanningConfig, Planning, Session, PlanningMetrics, InvalidConfigurationError
  - [ ] `src/validation.py`: Docstring pour validate_config() avec exemples Raises
  - [ ] `src/baseline.py`: Docstring pour generate_baseline() avec stratégie, args, returns, guarantees, performance
  - [ ] `src/metrics.py`: Docstrings pour compute_meeting_history() et compute_metrics() avec complexity notes
  - [ ] Vérifier format Google style:
    - Section Args: `param_name (type): Description`
    - Section Returns: `type: Description`
    - Section Raises: `ExceptionType: Conditions`
    - Section Examples (optionnel): code block avec `>>>`

- [ ] **Task 2: Créer exemple basic_usage.py** (AC: 3, 4)
  - [ ] Créer `examples/basic_usage.py`
  - [ ] Importer: PlanningConfig, validate_config, generate_baseline, compute_metrics
  - [ ] Étape 1: Créer config (N=30, X=5, x=6, S=6)
  - [ ] Étape 2: Valider config
  - [ ] Étape 3: Générer planning baseline avec seed=42
  - [ ] Étape 4: Calculer métriques
  - [ ] Étape 5: Afficher résultats:
    - Nombre de sessions, tables par session
    - Paires uniques totales
    - Écart équité (max_unique - min_unique)
    - Message si écart > 1: "Attention: équité non atteinte (optimisation nécessaire)"
  - [ ] Ajouter commentaires explicatifs français
  - [ ] Tester exécution: `python examples/basic_usage.py`

- [ ] **Task 3: Créer examples/README.md** (AC: 5)
  - [ ] Titre: "Exemples d'utilisation"
  - [ ] Section "basic_usage.py":
    - Description: "Démontre le pipeline baseline complet (Phase 1)"
    - Usage: `python examples/basic_usage.py`
    - Output attendu: métriques affichées console
  - [ ] Section "Prochains exemples":
    - Mentionner optimisation (Phase 2) et équité (Phase 3) à venir
    - Mentionner CLI à venir (Epic 3)

- [ ] **Task 4: Mettre à jour README.md principal** (AC: 2)
  - [ ] **Section 1: Description du projet** (2-3 paragraphes)
    - Présenter le problème: organisation d'événements de networking/speed dating avec rotation de tables
    - Objectif: maximiser rencontres uniques, minimiser répétitions, garantir équité (écart ≤1)
    - Solution: algorithme hybride 3 phases (baseline → optimisation → équité)
  - [ ] **Section 2: État du Projet**
    - MVP: Phase 1 (baseline) implémentée
    - Phase 2-3 (optimisation + équité): Epic 2
    - CLI interactive: Epic 3
  - [ ] **Section 3: Installation**
    ```bash
    # Cloner le repository
    git clone [url]
    cd speed-dating-planner

    # Installer avec Poetry
    poetry install

    # Ou avec pip (mode développement)
    pip install -e .
    ```
  - [ ] **Section 4: Utilisation rapide** (code Python 5-10 lignes)
    ```python
    from src.models import PlanningConfig
    from src.baseline import generate_baseline
    from src.metrics import compute_metrics

    config = PlanningConfig(N=30, X=5, x=6, S=6)
    planning = generate_baseline(config, seed=42)
    metrics = compute_metrics(planning, config)
    print(f"Paires uniques: {metrics.total_unique_pairs}")
    ```
  - [ ] **Section 5: Structure du projet** (arborescence)
    ```
    speed-dating-planner/
    ├── src/
    │   ├── models.py          # Data models
    │   ├── validation.py      # Config validation
    │   ├── baseline.py        # Phase 1: Baseline generation
    │   └── metrics.py         # Metrics calculation
    ├── tests/
    │   ├── test_models.py
    │   ├── test_validation.py
    │   ├── test_baseline.py
    │   ├── test_metrics.py
    │   └── test_integration_baseline.py
    ├── examples/
    │   ├── basic_usage.py     # Basic example
    │   └── README.md
    ├── docs/
    │   ├── prd.md             # Product requirements
    │   └── architecture/      # Technical architecture
    │       └── index.md       # Architecture entry point
    └── pyproject.toml
    ```
  - [ ] **Section 6: Architecture**
    - Lien vers `docs/architecture/index.md`
    - Mention 3 phases: baseline (round-robin) → amélioration locale → équité enforcement
  - [ ] **Section 7: Tests**
    ```bash
    # Tous tests
    pytest

    # Avec couverture
    pytest --cov=src --cov-report=term

    # Qualité code
    black .
    ruff check .
    mypy src/ --strict
    ```
  - [ ] **Section 8: Roadmap**
    - ✅ Epic 1: Pipeline Baseline + Métriques (MVP Phase 1)
    - ⏳ Epic 2: Optimisation + Équité (Phases 2-3)
    - ⏳ Epic 3: CLI Interactive
  - [ ] **Section 9: Licence**
    - MIT (ou autre selon choix)

- [ ] **Task 5: Valider docstrings avec pydocstyle (optionnel)** (AC: 1)
  - [ ] Installer pydocstyle si disponible: `poetry add --dev pydocstyle`
  - [ ] Configurer `.pydocstyle` pour convention Google
  - [ ] Exécuter: `pydocstyle src/`
  - [ ] Si pydocstyle pas disponible, validation manuelle via lecture code

- [ ] **Task 6: Tester l'exemple basic_usage.py** (AC: 4)
  - [ ] Exécuter: `python examples/basic_usage.py`
  - [ ] Vérifier output:
    - Affiche nombre de sessions, tables
    - Affiche métriques (paires uniques, écart)
    - Pas d'erreur, pas de warnings
  - [ ] Vérifier import paths corrects (src.models, src.baseline, etc.)

- [ ] **Task 7: Créer QA Gate YAML** (AC: 6)
  - [ ] Créer `docs/qa/gates/1.8-documentation.yml`
  - [ ] Checks:
    - Example execution: `python examples/basic_usage.py`
    - Black formatting: `black --check .`
    - Ruff linting: `ruff check .`
    - Mypy typing: `mypy src/ --strict`
    - Pytest all tests: `pytest tests/`
  - [ ] Expected outputs: tous passent

- [ ] **Task 8: Validation finale Documentation**
  - [ ] README.md complet avec toutes sections
  - [ ] examples/basic_usage.py s'exécute sans erreur
  - [ ] examples/README.md créé
  - [ ] Tous modules ont docstrings Google style
  - [ ] Liens vers architecture shardée fonctionnels
  - [ ] Mention CLI à venir présente
  - [ ] QA gate YAML créé

---

## Dev Notes

### Dépendance sur Stories Précédentes

**Stories 1.1-1.7 doivent TOUTES être complétées** :
- 1.1: Structure projet
- 1.2: Models
- 1.3: Validation
- 1.4: Baseline
- 1.5-1.6: Metrics
- 1.7: Integration tests

Cette story **documente** tout le code créé dans Epic 1.

### Docstring Google Style - Standards

[Source: docs/architecture/coding-standards.md]

**Format standard:**
```python
def compute_metrics(planning: Planning, config: PlanningConfig) -> PlanningMetrics:
    """
    Calcule toutes les métriques de qualité d'un planning (FR8-FR9).

    Métriques calculées:
    - Paires uniques et répétées
    - Statistiques d'équité par participant
    - Distribution tailles de tables

    Args:
        planning (Planning): Planning à analyser
        config (PlanningConfig): Configuration utilisée pour générer le planning

    Returns:
        PlanningMetrics: Métriques complètes avec statistiques d'équité

    Raises:
        ValueError: Si planning.config != config (incohérence)

    Performance:
        O(N²) - Utilise compute_meeting_history() puis calculs statistiques

    Examples:
        >>> config = PlanningConfig(N=30, X=5, x=6, S=6)
        >>> planning = generate_baseline(config, seed=42)
        >>> metrics = compute_metrics(planning, config)
        >>> print(metrics.equity_gap)  # max_unique - min_unique
        2
    """
    # Implementation...
```

**Sections obligatoires:**
- Description brève (1-2 lignes)
- Args: chaque paramètre avec type et description
- Returns: type de retour et description
- Raises: exceptions possibles (si applicable)

**Sections optionnelles:**
- Performance: complexité algorithmique
- Examples: code démonstration (si fonction non triviale)
- Notes: remarques importantes

### Exemple basic_usage.py - Structure Complète

**Objectif:** Démontrer le pipeline complet Phase 1 (baseline + métriques)

```python
"""
Exemple d'utilisation basique du système d'optimisation de tables rotatives.

Ce script démontre le pipeline baseline complet (Phase 1):
1. Créer et valider une configuration
2. Générer un planning baseline via round-robin
3. Calculer les métriques de qualité

Note: Les phases 2 (optimisation) et 3 (équité) seront implémentées dans Epic 2.
"""

from src.models import PlanningConfig
from src.validation import validate_config
from src.baseline import generate_baseline
from src.metrics import compute_metrics

def main():
    # Étape 1: Créer configuration
    # N=30 participants, X=5 tables, x=6 places/table, S=6 sessions
    config = PlanningConfig(N=30, X=5, x=6, S=6)
    print("Configuration créée:")
    print(f"  {config.N} participants, {config.X} tables de {config.x} places, {config.S} sessions\n")

    # Étape 2: Valider configuration
    try:
        validate_config(config)
        print("✓ Configuration valide\n")
    except Exception as e:
        print(f"✗ Configuration invalide: {e}")
        return

    # Étape 3: Générer planning baseline (Phase 1)
    print("Génération du planning baseline (Phase 1: Round-Robin)...")
    planning = generate_baseline(config, seed=42)
    print(f"✓ Planning généré: {len(planning.sessions)} sessions\n")

    # Étape 4: Calculer métriques
    print("Calcul des métriques de qualité...")
    metrics = compute_metrics(planning, config)

    # Affichage résultats
    print("\n=== MÉTRIQUES ===")
    print(f"Paires uniques totales: {metrics.total_unique_pairs}")
    print(f"Paires répétées: {metrics.total_repeat_pairs}")
    print(f"Rencontres uniques par personne:")
    print(f"  Min: {metrics.min_unique}")
    print(f"  Max: {metrics.max_unique}")
    print(f"  Moyenne: {metrics.mean_unique:.2f}")
    print(f"  Écart (max-min): {metrics.equity_gap}")

    # Vérification équité
    if metrics.equity_gap <= 1:
        print("\n✓ Équité atteinte (écart ≤1) !")
    else:
        print(f"\n⚠ Équité non atteinte (écart = {metrics.equity_gap})")
        print("  → Phases 2-3 (optimisation + équité) nécessaires (Epic 2)")

    print("\nNote: CLI interactive sera disponible dans Epic 3")
    print("Voir docs/architecture/index.md pour détails architecture")

if __name__ == "__main__":
    main()
```

### README.md - Structure Complète

**Sections obligatoires:**
1. Description projet (problème + solution)
2. État du projet (phases implémentées)
3. Installation
4. Utilisation rapide (code snippet)
5. Structure du projet
6. Architecture (lien vers docs)
7. Tests & qualité
8. Roadmap

**Ton:** Professionnel, clair, concis. Français.

### Liens vers Architecture Shardée

**Dans README.md:**
```markdown
## Architecture

Le système utilise un pipeline hybride en 3 phases:
1. **Baseline** (Round-Robin): Génération rapide d'un planning valide
2. **Amélioration Locale** (Greedy Swaps): Réduction des répétitions
3. **Équité Enforcement** (±1): Garantie d'équité stricte

Pour plus de détails, voir [docs/architecture/index.md](docs/architecture/index.md).
```

**Dans examples/README.md:**
```markdown
Pour comprendre l'architecture sous-jacente, consulter:
- [Architecture Overview](../docs/architecture/vue-densemble-de-larchitecture.md)
- [Data Models](../docs/architecture/modèles-de-données.md)
- [Module Interfaces](../docs/architecture/interfaces-entre-modules.md)
```

### Mention CLI à Venir

**Dans README.md - Section Roadmap:**
```markdown
## Roadmap

- ✅ **Epic 1: Pipeline Baseline + Métriques** (MVP Phase 1)
  - Génération baseline round-robin
  - Calcul métriques de qualité
  - Tests d'intégration

- ⏳ **Epic 2: Optimisation + Équité** (Phases 2-3)
  - Amélioration locale par swaps gloutons
  - Enforcement équité stricte (écart ≤1)

- ⏳ **Epic 3: CLI Interactive**
  - Interface en ligne de commande
  - Export JSON/CSV
  - Comparaison de plannings
```

**Dans examples/basic_usage.py (fin du script):**
```python
print("\nNote: CLI interactive sera disponible dans Epic 3")
print("  Exemple CLI futur: python -m src.cli generate --config config.json")
```

### Validation Docstrings

**Checklist manuelle (si pydocstyle pas disponible):**

Pour chaque fonction publique:
- [ ] Description brève présente (1-2 lignes)
- [ ] Section Args avec types et descriptions
- [ ] Section Returns avec type et description
- [ ] Section Raises si exceptions levées
- [ ] Format Google style respecté (indentation 4 espaces)
- [ ] Exemples si fonction non triviale

**Modules à vérifier:**
- `src/models.py`: PlanningConfig, Planning, Session, PlanningMetrics, InvalidConfigurationError
- `src/validation.py`: validate_config()
- `src/baseline.py`: generate_baseline()
- `src/metrics.py`: compute_meeting_history(), compute_metrics()

---

## Testing

### Approche de Testing pour Documentation

**Cette story est différente** des autres stories: pas de tests unitaires pytest, mais **validation par exécution**.

### Tests de Validation

**1. Exécution exemple basic_usage.py**
```bash
# Test principal: l'exemple doit s'exécuter sans erreur
python examples/basic_usage.py

# Output attendu:
Configuration créée:
  30 participants, 5 tables de 6 places, 6 sessions

✓ Configuration valide

Génération du planning baseline (Phase 1: Round-Robin)...
✓ Planning généré: 6 sessions

Calcul des métriques de qualité...

=== MÉTRIQUES ===
Paires uniques totales: [nombre]
Paires répétées: [nombre]
Rencontres uniques par personne:
  Min: [nombre]
  Max: [nombre]
  Moyenne: [nombre]
  Écart (max-min): [nombre]

[Message équité]

Note: CLI interactive sera disponible dans Epic 3
Voir docs/architecture/index.md pour détails architecture
```

**2. Vérification liens architecture**
```bash
# Les fichiers doivent exister
ls -la docs/architecture/index.md
ls -la docs/architecture/vue-densemble-de-larchitecture.md
ls -la docs/architecture/modèles-de-données.md
```

**3. Vérification qualité code**
```bash
# Black formatting
black --check examples/basic_usage.py

# Ruff linting
ruff check examples/basic_usage.py

# Mypy (si applicable)
mypy examples/basic_usage.py
```

**4. Vérification docstrings**
```bash
# Lecture manuelle de chaque module
cat src/models.py | grep -A 20 '"""'
cat src/validation.py | grep -A 20 '"""'
cat src/baseline.py | grep -A 20 '"""'
cat src/metrics.py | grep -A 20 '"""'

# Si pydocstyle disponible
pydocstyle src/
```

**5. Vérification README.md**
- [ ] Toutes les sections présentes
- [ ] Code snippets syntaxiquement corrects
- [ ] Liens fonctionnels (docs/architecture/index.md)
- [ ] Arborescence à jour

### Commandes de Test

```bash
# Test principal: exécution exemple
python examples/basic_usage.py

# Vérification qualité
black --check .
ruff check .
mypy src/ --strict

# Vérification exhaustive tests Epic 1
pytest tests/ -v

# Couverture
pytest tests/ --cov=src --cov-report=term --cov-fail-under=85
```

---

## QA Gate

**Fichier:** `docs/qa/gates/1.8-documentation.yml`

```yaml
story: 1.8-documentation
checks:
  - name: Example Execution
    command: python examples/basic_usage.py
    expected: Executes without error, displays metrics

  - name: README Structure
    command: cat README.md
    expected: All sections present (description, installation, usage, structure, architecture, tests, roadmap)

  - name: Architecture Links
    command: test -f docs/architecture/index.md && echo "✓ Architecture index exists"
    expected: Architecture index file exists

  - name: Examples README
    command: test -f examples/README.md && echo "✓ Examples README exists"
    expected: Examples README file exists

  - name: Code Formatting
    command: black --check examples/basic_usage.py README.md
    expected: All files formatted

  - name: Linting
    command: ruff check examples/basic_usage.py
    expected: No violations

  - name: Type Checking (if applicable)
    command: mypy examples/basic_usage.py || echo "Skipped (example script)"
    expected: No errors or skipped

  - name: All Tests Pass
    command: pytest tests/ -v
    expected: All Epic 1 tests pass

  - name: Coverage Threshold
    command: pytest tests/ --cov=src --cov-report=term --cov-fail-under=85
    expected: Coverage ≥85%

  - name: Docstrings Present
    command: grep -r '"""' src/*.py | wc -l
    expected: ">10 docstrings found"
```

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-10 | 1.0 | Story initiale créée par Scrum Master | Bob (SM) |

---

## Dev Agent Record

### Agent Model Used

_À compléter par le dev agent_

### Debug Log References

_À compléter par le dev agent_

### Completion Notes List

_À compléter par le dev agent_

### File List

_À compléter par le dev agent_

---

## QA Results

_À compléter par le QA agent_

---

**Definition of Done:**
- [ ] Tous les AC (1-6) sont satisfaits
- [ ] Toutes les tâches et sous-tâches sont complétées
- [ ] README.md mis à jour avec toutes sections requises
- [ ] examples/basic_usage.py créé et s'exécute sans erreur
- [ ] examples/README.md créé
- [ ] Tous modules ont docstrings Google style complètes
- [ ] Liens vers architecture shardée (docs/architecture/index.md) fonctionnels
- [ ] Mention CLI à venir (Epic 3) présente dans README et exemple
- [ ] QA Gate YAML créé dans `docs/qa/gates/1.8-documentation.yml`
- [ ] `black` et `ruff` passent sur examples/basic_usage.py
- [ ] Tous tests Epic 1 (tests/) passent
- [ ] Couverture ≥85% pour tous modules src/
- [ ] **Granularité:** 1 story = 1 PR (documentation Epic 1)
