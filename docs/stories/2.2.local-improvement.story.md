# Story 2.2: Implémenter l'Amélioration Locale par Swaps Gloutons

## Status

**Draft**

---

## Story

**As a** organisateur d'événement,
**I want** que le système améliore automatiquement la qualité du planning baseline,
**so that** je reçois un planning avec le minimum de répétitions possible.

---

## Acceptance Criteria

1. Une fonction `improve_planning(planning: Planning, config: PlanningConfig, max_iterations: int = 100) -> Planning` dans `src/optimizer.py`
2. L'algorithme itère sur toutes les sessions et teste des swaps entre tables
3. À chaque itération, si un swap améliore le score (réduit répétitions), il est appliqué
4. L'algorithme s'arrête quand aucune amélioration n'est trouvée (plateau local) ou max_iterations atteint
5. Un système de logging (niveau INFO) indique : "Itération X: Y swaps appliqués, Z répétitions éliminées"
6. Les tests vérifient :
   - Planning avec répétitions connues → amélioration mesurable après `improve_planning`
   - Détection du plateau local (stop avant max_iterations si plus d'améliorations)
   - Déterminisme (seed fixe → même résultat)
   - Performance : amélioration pour N=100, S=10 en <3s
7. Le planning retourné est toujours valide (tous participants assignés, contraintes respectées)

---

## Tasks / Subtasks

- [ ] **Task 1: Implémenter improve_planning() - signature et docstring** (AC: 1)
  - [ ] Créer fonction dans `src/optimizer.py`:
    ```python
    def improve_planning(
        planning: Planning,
        config: PlanningConfig,
        max_iterations: int = 100
    ) -> Planning
    ```
  - [ ] Docstring Google style:
    - Description: "Améliore un planning via swaps gloutons locaux (Phase 2)"
    - Stratégie: itérations, test swaps, application si amélioration, arrêt plateau local
    - Args avec types et defaults
    - Returns: "Planning amélioré avec répétitions réduites"
    - Complexity: O(iter × S × X² × x²) - contrôlé par max_iterations et plateau

- [ ] **Task 2: Implémenter structure boucle principale** (AC: 2, 4)
  - [ ] Initialiser variables:
    ```python
    current_planning = planning
    iteration = 0
    total_swaps = 0
    ```
  - [ ] Boucle while `iteration < max_iterations`:
    - Calculer `met_pairs = compute_meeting_history(current_planning)`
    - Initialiser `swaps_this_iteration = 0`
    - Itérer sur sessions, tables, participants
    - Si aucun swap cette itération: break (plateau local)
    - Sinon: `iteration += 1`

- [ ] **Task 3: Implémenter parcours sessions et tables** (AC: 2, 3)
  - [ ] Pour chaque session:
    ```python
    for session_id, session in enumerate(current_planning.sessions):
        for t1_id in range(len(session.tables)):
            for t2_id in range(t1_id + 1, len(session.tables)):
    ```
  - [ ] Récupérer listes participants:
    ```python
    table1 = list(session.tables[t1_id])
    table2 = list(session.tables[t2_id])
    ```
  - [ ] Tester tous swaps possibles entre table1 et table2

- [ ] **Task 4: Implémenter évaluation et application swaps** (AC: 3)
  - [ ] Double boucle participants:
    ```python
    for p1 in table1:
        for p2 in table2:
            delta = evaluate_swap(
                current_planning, session_id,
                t1_id, p1, t2_id, p2, met_pairs
            )
            if delta < 0:  # Amélioration
                # Appliquer swap
                session.tables[t1_id].remove(p1)
                session.tables[t1_id].add(p2)
                session.tables[t2_id].remove(p2)
                session.tables[t2_id].add(p1)
                swaps_this_iteration += 1
                # Recalcul historique après changement
                met_pairs = compute_meeting_history(current_planning)
    ```

- [ ] **Task 5: Implémenter logging Phase 2** (AC: 5)
  - [ ] Après chaque itération:
    ```python
    logger.info(f"Itération {iteration + 1}: {swaps_this_iteration} swaps appliqués")
    ```
  - [ ] Si plateau local:
    ```python
    logger.info(f"Plateau local atteint après {iteration + 1} itérations")
    break
    ```
  - [ ] À la fin:
    ```python
    logger.info(f"Amélioration terminée : {total_swaps} swaps totaux, "
                f"{iteration + 1} itérations")
    ```

- [ ] **Task 6: Créer tests test_optimizer.py pour improve_planning** (AC: 6, 7)
  - [ ] Compléter `tests/test_optimizer.py` avec tests amélioration locale
  - [ ] Fonction helper: `create_planning_with_repeats()` pour plannings contrôlés

- [ ] **Task 7: Test amélioration mesurable** (AC: 6)
  - [ ] Créer planning baseline avec répétitions connues:
    - N=12, X=3, x=4, S=3
    - Forcer répétitions via construction manuelle
  - [ ] Calculer métriques avant: `metrics_before = compute_metrics(planning_before, config)`
  - [ ] Appliquer: `planning_after = improve_planning(planning_before, config)`
  - [ ] Calculer métriques après: `metrics_after = compute_metrics(planning_after, config)`
  - [ ] Vérifier: `metrics_after.total_repeat_pairs < metrics_before.total_repeat_pairs`
  - [ ] Vérifier réduction ≥50% (ou autre seuil approprié)

- [ ] **Task 8: Test détection plateau local** (AC: 4, 6)
  - [ ] Créer planning déjà optimisé (aucun swap bénéfique possible)
  - [ ] Appliquer improve_planning avec max_iterations=100
  - [ ] Vérifier arrêt avant max_iterations (plateau détecté)
  - [ ] Vérifier log contient "Plateau local atteint après X itérations" avec X < 100

- [ ] **Task 9: Test déterminisme** (AC: 6)
  - [ ] Créer planning baseline: `generate_baseline(config, seed=42)`
  - [ ] Améliorer 2 fois:
    - `planning1 = improve_planning(baseline, config)`
    - `baseline2 = generate_baseline(config, seed=42)`  # Re-générer pour reset
    - `planning2 = improve_planning(baseline2, config)`
  - [ ] Vérifier planning1 == planning2 (mêmes tables, même ordre)
  - [ ] Note: déterminisme dépend de l'ordre parcours (fixe dans code)

- [ ] **Task 10: Test performance N=100 <3s** (AC: 6)
  - [ ] Marquer test avec `@pytest.mark.slow`
  - [ ] Config: N=100, X=20, x=5, S=10
  - [ ] Générer baseline: `planning = generate_baseline(config, seed=42)`
  - [ ] Mesurer temps:
    ```python
    import time
    start = time.time()
    improved = improve_planning(planning, config, max_iterations=50)
    elapsed = time.time() - start
    ```
  - [ ] Assert: `elapsed < 3.0` secondes
  - [ ] Vérifier amélioration effective (total_repeat_pairs réduit)

- [ ] **Task 11: Test planning retourné valide** (AC: 7)
  - [ ] Après improve_planning, vérifier invariants:
    - Tous participants présents chaque session
    - Aucun participant dupliqué dans une session
    - Tailles tables respectent contraintes (écart ≤1)
    - Nombre total participants = config.N
  - [ ] Helper function: `validate_planning_structure(planning, config)`

- [ ] **Task 12: Test cas limite max_iterations atteint** (AC: 4)
  - [ ] Créer planning avec beaucoup de répétitions
  - [ ] Appliquer avec max_iterations=5 (très bas)
  - [ ] Vérifier fonction s'arrête après exactement 5 itérations
  - [ ] Vérifier amélioration partielle (pas optimale)

- [ ] **Task 13: Valider couverture et qualité**
  - [ ] `pytest tests/test_optimizer.py::test_improve -v`
  - [ ] `pytest tests/test_optimizer.py --cov=src.optimizer --cov-report=term`
  - [ ] Vérifier couverture ≥90%
  - [ ] `mypy src/optimizer.py --strict`
  - [ ] `black` et `ruff` passent

- [ ] **Task 14: Créer QA Gate YAML**
  - [ ] Créer `docs/qa/gates/2.2-local-improvement.yml`
  - [ ] Checks: pytest (fast + slow), mypy, black, ruff, coverage ≥90%

---

## Dev Notes

### Dépendance sur Stories Précédentes

**Stories 2.1 et Epic 1 doivent être complétées** :
- Epic 1 (1.1-1.7): Models, baseline, metrics
- 2.1: evaluate_swap() primitive

Cette story implémente **Phase 2 du pipeline** (amélioration locale).

### Implémentation Exacte - improve_planning()

[Source: docs/architecture/interfaces-entre-modules.md#3.5]

```python
import logging
from src.models import Planning, PlanningConfig
from src.metrics import compute_meeting_history
from src.optimizer import evaluate_swap

logger = logging.getLogger(__name__)


def improve_planning(
    planning: Planning,
    config: PlanningConfig,
    max_iterations: int = 100
) -> Planning:
    """
    Améliore un planning via swaps gloutons locaux (Phase 2).

    Stratégie:
    - Itérations sur toutes les sessions
    - Test swaps entre tables de chaque session
    - Application si amélioration (delta < 0)
    - Arrêt si plateau local (aucune amélioration) ou max_iterations

    Args:
        planning (Planning): Planning baseline à améliorer
        config (PlanningConfig): Configuration
        max_iterations (int): Nombre max d'itérations (default: 100)

    Returns:
        Planning: Planning amélioré avec répétitions réduites

    Guarantees:
        - Planning retourné est valide (tous participants assignés)
        - Répétitions réduites (ou égales si déjà optimal)
        - Arrêt garanti (plateau ou max_iterations)

    Complexity:
        O(iter × S × X² × x²) - contrôlé par max_iterations et plateau

    Performance:
        N=100, S=10: ~1-3s (dépend de la qualité baseline)

    Examples:
        >>> config = PlanningConfig(N=30, X=5, x=6, S=6)
        >>> baseline = generate_baseline(config, seed=42)
        >>> improved = improve_planning(baseline, config)
        >>> # improved a moins de répétitions que baseline
    """
    # Note: Pour MVP, on recalcule historique à chaque itération (simple)
    # Optimisation future: tracking incrémental

    current_planning = planning
    iteration = 0
    total_swaps = 0

    while iteration < max_iterations:
        met_pairs = compute_meeting_history(current_planning)
        swaps_this_iteration = 0

        for session_id, session in enumerate(current_planning.sessions):
            for t1_id in range(len(session.tables)):
                for t2_id in range(t1_id + 1, len(session.tables)):
                    table1 = list(session.tables[t1_id])
                    table2 = list(session.tables[t2_id])

                    # Tester swaps possibles
                    for p1 in table1:
                        for p2 in table2:
                            delta = evaluate_swap(
                                current_planning, session_id,
                                t1_id, p1, t2_id, p2, met_pairs
                            )
                            if delta < 0:  # Amélioration
                                # Appliquer swap
                                session.tables[t1_id].remove(p1)
                                session.tables[t1_id].add(p2)
                                session.tables[t2_id].remove(p2)
                                session.tables[t2_id].add(p1)
                                swaps_this_iteration += 1
                                # Recalcul historique après changement
                                met_pairs = compute_meeting_history(current_planning)

        total_swaps += swaps_this_iteration
        logger.info(f"Itération {iteration + 1}: {swaps_this_iteration} swaps appliqués")

        if swaps_this_iteration == 0:
            logger.info(f"Plateau local atteint après {iteration + 1} itérations")
            break

        iteration += 1

    logger.info(f"Amélioration terminée : {total_swaps} swaps totaux, "
                f"{iteration + 1} itérations")
    return current_planning
```

### Algorithme Glouton Local - Explications

**Approche:** Greedy local search (recherche locale gloutonne)

**Principe:**
1. À chaque itération, parcourir toutes les paires de tables dans toutes les sessions
2. Pour chaque paire de tables, tester tous les swaps possibles entre participants
3. Si un swap réduit les répétitions (delta < 0), l'appliquer immédiatement
4. Continuer jusqu'à ce qu'aucun swap bénéfique ne soit trouvé (optimum local)

**Garanties:**
- ✅ Converge toujours (plateau local garanti)
- ✅ Ne dégrade jamais la qualité (swaps uniquement si delta < 0)
- ✅ Réduit répétitions autant que possible dans limite de l'optimum local
- ❌ Ne garantit PAS l'optimum global (peut rester bloqué dans optimum local)

**Pourquoi "glouton" ?**
- Applique swap dès qu'amélioration trouvée (pas d'exploration exhaustive)
- Ne revient jamais en arrière (pas de backtracking)
- Rapide mais pas optimal global

### Complexité Algorithmique Détaillée

**Temps:** O(iter × S × X² × x²)

Décomposition:
```python
while iteration < max_iterations:           # O(iter)
    met_pairs = compute_meeting_history()   # O(S × X × x²)
    for session in sessions:                # O(S)
        for t1_id in range(X):               # O(X)
            for t2_id in range(t1_id+1, X):  # O(X)
                for p1 in table1:             # O(x)
                    for p2 in table2:         # O(x)
                        evaluate_swap()       # O(x)
```

**Facteur dominant:** O(iter × S × X² × x²)

**Cas pratique:**
- N=100, X=20, x=5, S=10, iter≈10
- Ops: 10 × 10 × 400 × 25 = 1,000,000 ops
- Temps: ~1-3s (CPU moderne)

**Optimisations possibles (post-MVP):**
- Tracking incrémental met_pairs (éviter recalcul complet)
- Early stopping per session si aucun swap
- Parallelisation sessions (swaps indépendants)

### Plateau Local vs Max Iterations

**Plateau Local:**
- Aucun swap bénéfique trouvé dans itération complète
- Optimum local atteint
- Arrêt anticipé (meilleure performance)

**Max Iterations:**
- Limite supérieure pour éviter boucles infinies (sécurité)
- Si atteint: planning partiellement optimisé
- Default 100 itérations (généreux pour MVP)

**Logs pour distinguer:**
```
# Plateau local
INFO: Itération 12: 0 swaps appliqués
INFO: Plateau local atteint après 12 itérations
INFO: Amélioration terminée : 47 swaps totaux, 12 itérations

# Max iterations
INFO: Itération 100: 3 swaps appliqués
INFO: Amélioration terminée : 523 swaps totaux, 100 itérations
```

### Déterminisme de l'Algorithme

**Déterminisme garanti SI:**
- Ordre parcours fixe (oui: `enumerate(sessions)`, `range(X)`, `list(table)`)
- Pas d'aléatoire (oui: aucun `random`)
- Planning baseline identique (oui si même seed)

**Donc:**
- Même baseline + même config → même planning amélioré
- Test déterminisme: générer 2× baseline (seed=42), améliorer 2×, comparer

**Note:** Sets Python sont ordonnés depuis Python 3.7+ (ordre insertion), donc `list(table)` est déterministe.

### Logging et Traçabilité

**Niveaux de logging:**
- INFO: Progression itérations, détection plateau, résumé final
- DEBUG (futur): Détails chaque swap appliqué

**Messages clés:**
```python
logger.info(f"Itération {iteration + 1}: {swaps_this_iteration} swaps appliqués")
logger.info(f"Plateau local atteint après {iteration + 1} itérations")
logger.info(f"Amélioration terminée : {total_swaps} swaps totaux, {iteration + 1} itérations")
```

**Utilité:**
- Monitoring progression temps réel
- Debugging configurations difficiles
- Validation convergence

---

## Testing

### Test Coverage Target: ≥90%

**Module critique Phase 2**, couverture élevée requise.

### Tests Exhaustifs Requis

**1. Test amélioration mesurable**
```python
from src.baseline import generate_baseline
from src.metrics import compute_metrics
from src.optimizer import improve_planning

def test_improve_planning_reduces_repeats():
    """Test que amélioration réduit répétitions."""
    config = PlanningConfig(N=30, X=5, x=6, S=6)

    # Baseline avec répétitions attendues
    baseline = generate_baseline(config, seed=42)
    metrics_before = compute_metrics(baseline, config)

    # Amélioration
    improved = improve_planning(baseline, config)
    metrics_after = compute_metrics(improved, config)

    # Vérifier réduction répétitions
    assert metrics_after.total_repeat_pairs < metrics_before.total_repeat_pairs
    # Vérifier réduction significative (au moins 30%)
    reduction_pct = (metrics_before.total_repeat_pairs - metrics_after.total_repeat_pairs) / metrics_before.total_repeat_pairs
    assert reduction_pct >= 0.3, f"Réduction seulement {reduction_pct*100:.1f}% (attendu ≥30%)"
```

**2. Test détection plateau local**
```python
def test_improve_planning_plateau_detection(caplog):
    """Test détection plateau local et arrêt anticipé."""
    config = PlanningConfig(N=12, X=3, x=4, S=2)
    baseline = generate_baseline(config, seed=42)

    # Améliorer avec max_iterations élevé
    with caplog.at_level(logging.INFO):
        improved = improve_planning(baseline, config, max_iterations=100)

    # Vérifier présence message plateau local
    assert any("Plateau local atteint" in record.message for record in caplog.records)

    # Vérifier arrêt avant max_iterations
    final_log = caplog.records[-1].message
    # Extraire nombre itérations du log
    assert "itérations" in final_log
    # Le nombre d'itérations doit être < 100
```

**3. Test déterminisme**
```python
def test_improve_planning_deterministic():
    """Test reproductibilité amélioration."""
    config = PlanningConfig(N=30, X=5, x=6, S=6)

    # Générer et améliorer 2 fois avec même seed
    baseline1 = generate_baseline(config, seed=42)
    improved1 = improve_planning(baseline1, config)

    baseline2 = generate_baseline(config, seed=42)
    improved2 = improve_planning(baseline2, config)

    # Vérifier identité complète
    for s_idx in range(config.S):
        for t_idx in range(config.X):
            assert improved1.sessions[s_idx].tables[t_idx] == \
                   improved2.sessions[s_idx].tables[t_idx]
```

**4. Test performance N=100 <3s**
```python
import time
import pytest

@pytest.mark.slow
def test_improve_planning_performance_n100():
    """Test performance amélioration N=100 <3s."""
    config = PlanningConfig(N=100, X=20, x=5, S=10)
    baseline = generate_baseline(config, seed=42)

    start = time.time()
    improved = improve_planning(baseline, config, max_iterations=50)
    elapsed = time.time() - start

    assert elapsed < 3.0, f"Amélioration trop lente: {elapsed:.3f}s (limite 3s)"

    # Vérifier amélioration effective
    metrics = compute_metrics(improved, config)
    assert metrics.total_repeat_pairs < metrics.total_unique_pairs  # Au moins quelques répétitions éliminées
```

**5. Test planning retourné valide**
```python
def test_improve_planning_valid_output():
    """Test planning amélioré reste valide."""
    config = PlanningConfig(N=30, X=5, x=6, S=6)
    baseline = generate_baseline(config, seed=42)
    improved = improve_planning(baseline, config)

    # Vérifier invariants
    for session in improved.sessions:
        # Tous participants présents
        all_participants = set()
        for table in session.tables:
            all_participants.update(table)
        assert len(all_participants) == config.N
        assert all_participants == set(range(config.N))

        # Tailles tables correctes
        sizes = [len(table) for table in session.tables]
        assert max(sizes) - min(sizes) <= 1  # FR7
```

**6. Test cas limite max_iterations atteint**
```python
def test_improve_planning_max_iterations_limit():
    """Test arrêt si max_iterations atteint."""
    config = PlanningConfig(N=30, X=5, x=6, S=6)
    baseline = generate_baseline(config, seed=42)

    # Forcer max_iterations très bas
    improved = improve_planning(baseline, config, max_iterations=3)

    # Fonction doit retourner un planning valide même si non optimal
    assert len(improved.sessions) == config.S
    # Amélioration partielle acceptable
```

### Commandes de Test

```bash
# Tests unitaires rapides
pytest tests/test_optimizer.py::test_improve -v -m "not slow"

# Tests performance
pytest tests/test_optimizer.py::test_improve -v -m "slow"

# Tous tests
pytest tests/test_optimizer.py -v

# Couverture
pytest tests/test_optimizer.py --cov=src.optimizer --cov-report=term --cov-fail-under=90

# Type checking
mypy src/optimizer.py --strict

# Qualité code
black src/optimizer.py tests/test_optimizer.py
ruff check src/optimizer.py tests/test_optimizer.py
```

---

## QA Gate

**Fichier:** `docs/qa/gates/2.2-local-improvement.yml`

```yaml
story: 2.2-local-improvement
checks:
  - name: Unit Tests (Fast)
    command: pytest tests/test_optimizer.py::test_improve -v -m "not slow"
    expected: All tests pass

  - name: Performance Tests (Slow)
    command: pytest tests/test_optimizer.py::test_improve -v -m "slow"
    expected: N=100 improvement <3s

  - name: Coverage
    command: pytest tests/test_optimizer.py --cov=src.optimizer --cov-report=term --cov-fail-under=90
    expected: Coverage ≥90%

  - name: Type Checking
    command: mypy src/optimizer.py --strict
    expected: No errors

  - name: Code Formatting
    command: black --check src/optimizer.py tests/test_optimizer.py
    expected: All files formatted

  - name: Linting
    command: ruff check src/optimizer.py tests/test_optimizer.py
    expected: No violations

  - name: Plateau Detection Test
    command: pytest tests/test_optimizer.py::test_improve_planning_plateau_detection -v
    expected: Plateau local detected and logged

  - name: Determinism Test
    command: pytest tests/test_optimizer.py::test_improve_planning_deterministic -v
    expected: Same seed → same improved planning
```

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-10 | 1.0 | Story initiale créée par Scrum Master | Bob (SM) |

---

## Dev Agent Record

### Agent Model Used

_À compléter par le dev agent_

### Debug Log References

_À compléter par le dev agent_

### Completion Notes List

_À compléter par le dev agent_

### File List

_À compléter par le dev agent_

---

## QA Results

_À compléter par le QA agent_

---

**Definition of Done:**
- [ ] Tous les AC (1-7) sont satisfaits
- [ ] Toutes les tâches et sous-tâches sont complétées
- [ ] `improve_planning()` implémentée dans `src/optimizer.py`
- [ ] Tests unitaires `test_improve_planning_*` dans `tests/test_optimizer.py`
- [ ] Test amélioration mesurable: répétitions réduites ≥30%
- [ ] Test plateau local: détecté et loggé
- [ ] Test déterminisme: même seed → même résultat
- [ ] Test performance: N=100 amélioration <3s (`@pytest.mark.slow`)
- [ ] Test validité: planning retourné respecte tous invariants
- [ ] Couverture ≥90%
- [ ] `mypy --strict` passe sans erreur
- [ ] `black` et `ruff` passent sans erreur
- [ ] Logging Phase 2: itérations, swaps, plateau local
- [ ] QA Gate YAML créé dans `docs/qa/gates/2.2-local-improvement.yml`
- [ ] Docstring complète avec complexité O(iter×S×X²×x²)
- [ ] **Granularité:** 1 story = 1 PR (amélioration locale uniquement)
