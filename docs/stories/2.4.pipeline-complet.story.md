# Story 2.4: Implémenter le Pipeline Complet d'Optimisation

## Status

**Draft**

---

## Story

**As a** développeur,
**I want** une fonction orchestrant les 3 phases du pipeline hybride,
**so that** je peux générer des plannings optimisés en un seul appel de fonction.

---

## Acceptance Criteria

1. Un module `src/planner.py` contient une fonction `generate_optimized_planning(config: PlanningConfig, seed: int = 42) -> Tuple[Planning, PlanningMetrics]`
2. La fonction exécute séquentiellement :
   - Phase 1 : `generate_baseline(config, seed)`
   - Phase 2 : `improve_planning(baseline, config)`
   - Phase 3 : `enforce_equity(improved, config)`
   - Calcul final : `compute_metrics(final_planning, config)`
3. Chaque phase logue son exécution (niveau INFO) : "Phase 1: Baseline générée", "Phase 2: X répétitions éliminées", "Phase 3: Équité garantie"
4. La fonction retourne le planning final ET ses métriques
5. Les tests vérifient :
   - Pipeline complet pour config standard (N=30) réussit
   - Métriques finales confirment FR6 (équité ±1)
   - Planning final est valide (aucun participant oublié)
6. La fonction gère les configurations impossibles (S × (x-1) < N-1) en loguant un WARNING mais produit quand même le meilleur planning possible

---

## Tasks / Subtasks

- [ ] **Task 1: Créer module planner.py** (AC: 1)
  - [ ] Créer `src/planner.py`
  - [ ] Importer: logging, Tuple from typing
  - [ ] Importer: Planning, PlanningConfig, PlanningMetrics from src.models
  - [ ] Importer: validate_config from src.validation
  - [ ] Importer: generate_baseline from src.baseline
  - [ ] Importer: improve_planning, enforce_equity from src.optimizer
  - [ ] Importer: compute_metrics from src.metrics
  - [ ] Initialiser logger

- [ ] **Task 2: Implémenter generate_optimized_planning() signature** (AC: 1, 4)
  - [ ] Créer fonction:
    ```python
    def generate_optimized_planning(
        config: PlanningConfig,
        seed: int = 42
    ) -> Tuple[Planning, PlanningMetrics]
    ```
  - [ ] Docstring Google style complète:
    - Description: Pipeline 3 phases
    - Args, Returns, Raises
    - Example usage
    - Performance attendue

- [ ] **Task 3: Implémenter validation et détection config impossible** (AC: 6)
  - [ ] Appeler validate_config:
    ```python
    validate_config(config)
    logger.info(f"Configuration validée : N={config.N}, X={config.X}, x={config.x}, S={config.S}")
    ```
  - [ ] Détecter configuration mathématiquement impossible:
    ```python
    max_possible_meetings = config.S * (config.x - 1)
    min_needed_meetings = config.N - 1
    if max_possible_meetings < min_needed_meetings:
        logger.warning(
            f"Configuration mathématiquement impossible pour zéro répétition : "
            f"S×(x-1) = {max_possible_meetings} < N-1 = {min_needed_meetings}. "
            f"Le planning minimisera les répétitions tout en garantissant l'équité."
        )
    ```

- [ ] **Task 4: Implémenter Phase 1 - Baseline** (AC: 2, 3)
  - [ ] Logger début:
    ```python
    logger.info("Phase 1 : Génération baseline...")
    ```
  - [ ] Générer baseline:
    ```python
    planning = generate_baseline(config, seed)
    ```
  - [ ] Logger fin:
    ```python
    logger.info("Phase 1 : Baseline générée ✓")
    ```

- [ ] **Task 5: Implémenter Phase 2 - Amélioration locale** (AC: 2, 3)
  - [ ] Logger début + appel:
    ```python
    logger.info("Phase 2 : Amélioration locale...")
    planning = improve_planning(planning, config)
    logger.info("Phase 2 : Amélioration terminée ✓")
    ```

- [ ] **Task 6: Implémenter Phase 3 - Équité** (AC: 2, 3)
  - [ ] Logger début + appel:
    ```python
    logger.info("Phase 3 : Enforcement équité...")
    planning = enforce_equity(planning, config)
    logger.info("Phase 3 : Équité garantie ✓")
    ```

- [ ] **Task 7: Calcul métriques finales et retour** (AC: 4)
  - [ ] Calculer métriques:
    ```python
    metrics = compute_metrics(planning, config)
    ```
  - [ ] Logger résumé:
    ```python
    logger.info(f"Métriques finales : {metrics.total_unique_pairs} paires uniques, "
                f"{metrics.total_repeat_pairs} répétitions, "
                f"équité {metrics.min_unique}-{metrics.max_unique} "
                f"(écart {metrics.equity_gap})")
    ```
  - [ ] Retourner tuple:
    ```python
    return planning, metrics
    ```

- [ ] **Task 8: Créer tests test_planner.py** (AC: 5)
  - [ ] Créer `tests/test_planner.py`
  - [ ] Importer: pytest, logging, Planning, PlanningConfig, generate_optimized_planning, compute_metrics

- [ ] **Task 9: Test pipeline complet N=30** (AC: 5)
  - [ ] Config: N=30, X=5, x=6, S=6
  - [ ] Appeler generate_optimized_planning
  - [ ] Vérifier retour: (Planning, PlanningMetrics)
  - [ ] Vérifier métriques finales: equity_gap ≤ 1
  - [ ] Vérifier planning valide: tous participants présents chaque session

- [ ] **Task 10: Test garantie FR6** (AC: 5)
  - [ ] Plusieurs configs (N=30, N=50, N=100)
  - [ ] Pour chaque config:
    - Appeler generate_optimized_planning
    - Assert metrics.equity_gap ≤ 1
    - Assert tous participants dans [min, min+1]

- [ ] **Task 11: Test configuration impossible** (AC: 6)
  - [ ] Config impossible: N=32, S=3, X=4, x=8
    - S×(x-1) = 3×7 = 21 < N-1 = 31
  - [ ] Capturer logs (caplog)
  - [ ] Appeler generate_optimized_planning
  - [ ] Vérifier WARNING loggé avec message "impossible"
  - [ ] Vérifier planning généré quand même
  - [ ] Vérifier équité ±1 respectée malgré impossibilité zéro répétitions

- [ ] **Task 12: Test logging phases** (AC: 3)
  - [ ] Capturer logs INFO
  - [ ] Appeler generate_optimized_planning
  - [ ] Vérifier présence:
    - "Phase 1 : Baseline générée"
    - "Phase 2 : Amélioration terminée"
    - "Phase 3 : Équité garantie"
    - "Métriques finales :"

- [ ] **Task 13: Valider couverture et qualité**
  - [ ] `pytest tests/test_planner.py -v`
  - [ ] `pytest tests/test_planner.py --cov=src.planner --cov-report=term --cov-fail-under=95`
  - [ ] `mypy src/planner.py --strict`
  - [ ] `black` et `ruff` passent

- [ ] **Task 14: Créer QA Gate YAML**
  - [ ] Créer `docs/qa/gates/2.4-pipeline-complet.yml`
  - [ ] Checks: pytest, mypy, black, ruff, coverage ≥95%

---

## Dev Notes

### Dépendance sur Stories Précédentes

**Epic 1 complet + Stories 2.1-2.3 complètes:**
- Epic 1: baseline, metrics
- 2.1-2.3: evaluate_swap, improve_planning, enforce_equity

Cette story **orchestre** toutes les phases du pipeline en une fonction unique.

### Implémentation Exacte

[Source: docs/architecture/interfaces-entre-modules.md#3.6]

Code complet dans architecture (voir module planner.py section 3.6).

**Fonction principale:**
```python
def generate_optimized_planning(
    config: PlanningConfig,
    seed: int = 42
) -> Tuple[Planning, PlanningMetrics]:
    # Validation
    validate_config(config)

    # Détection impossible
    if S*(x-1) < N-1:
        logger.warning(...)

    # Phase 1
    planning = generate_baseline(config, seed)

    # Phase 2
    planning = improve_planning(planning, config)

    # Phase 3
    planning = enforce_equity(planning, config)

    # Métriques
    metrics = compute_metrics(planning, config)

    return planning, metrics
```

### Configuration Mathématiquement Impossible

**Critère:** `S × (x-1) < N-1`

**Signification:**
- Maximum rencontres possibles par personne: `S × (x-1)` (chaque session, table de taille x → x-1 autres participants)
- Minimum requis pour tout le monde se rencontre au moins 1×: `N-1`
- Si max < min → impossible zéro répétition

**Exemple:**
- N=32, S=3, x=8
- Max: 3 × 7 = 21 rencontres/personne
- Min requis: 31 rencontres/personne
- → Impossible, des répétitions inévitables

**Gestion:**
- WARNING loggé (pas d'erreur)
- Pipeline continue
- Produit meilleur planning possible (minimal répétitions + équité garantie)

---

## Testing

### Tests Requis

**1. Pipeline complet réussit**
```python
def test_generate_optimized_planning_success():
    config = PlanningConfig(N=30, X=5, x=6, S=6)
    planning, metrics = generate_optimized_planning(config, seed=42)

    assert isinstance(planning, Planning)
    assert isinstance(metrics, PlanningMetrics)
    assert metrics.equity_gap <= 1
    assert len(planning.sessions) == 6
```

**2. Garantie FR6 pour multiples configs**
```python
@pytest.mark.parametrize("N,X,x,S", [(30,5,6,6), (50,10,5,8), (100,20,5,10)])
def test_generate_optimized_planning_fr6_guarantee(N,X,x,S):
    config = PlanningConfig(N=N, X=X, x=x, S=S)
    planning, metrics = generate_optimized_planning(config)
    assert metrics.equity_gap <= 1
```

**3. Configuration impossible loggée**
```python
def test_generate_optimized_planning_impossible_config(caplog):
    config = PlanningConfig(N=32, X=4, x=8, S=3)
    with caplog.at_level(logging.WARNING):
        planning, metrics = generate_optimized_planning(config)
    assert any("impossible" in record.message.lower() for record in caplog.records)
    assert metrics.equity_gap <= 1  # Équité quand même garantie
```

**4. Logging phases présent**
```python
def test_generate_optimized_planning_logging(caplog):
    config = PlanningConfig(N=30, X=5, x=6, S=6)
    with caplog.at_level(logging.INFO):
        planning, metrics = generate_optimized_planning(config)

    messages = [r.message for r in caplog.records]
    assert any("Phase 1" in m and "Baseline" in m for m in messages)
    assert any("Phase 2" in m and "Amélioration" in m for m in messages)
    assert any("Phase 3" in m and "Équité" in m for m in messages)
```

---

## QA Gate

**Fichier:** `docs/qa/gates/2.4-pipeline-complet.yml`

```yaml
story: 2.4-pipeline-complet
checks:
  - name: Unit Tests
    command: pytest tests/test_planner.py -v
    expected: All tests pass

  - name: FR6 Guarantee
    command: pytest tests/test_planner.py::test_generate_optimized_planning_fr6_guarantee -v
    expected: equity_gap ≤ 1 for all configs

  - name: Impossible Config Handling
    command: pytest tests/test_planner.py::test_generate_optimized_planning_impossible_config -v
    expected: WARNING logged, planning generated

  - name: Coverage
    command: pytest tests/test_planner.py --cov=src.planner --cov-report=term --cov-fail-under=95
    expected: Coverage ≥95%

  - name: Type Checking
    command: mypy src/planner.py --strict
    expected: No errors

  - name: Code Formatting
    command: black --check src/planner.py tests/test_planner.py
    expected: All files formatted

  - name: Linting
    command: ruff check src/planner.py tests/test_planner.py
    expected: No violations
```

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-10 | 1.0 | Story initiale créée par Scrum Master | Bob (SM) |

---

## Dev Agent Record

### Agent Model Used

_À compléter par le dev agent_

### Debug Log References

_À compléter par le dev agent_

### Completion Notes List

_À compléter par le dev agent_

### File List

_À compléter par le dev agent_

---

## QA Results

_À compléter par le QA agent_

---

**Definition of Done:**
- [ ] Tous les AC (1-6) sont satisfaits
- [ ] Toutes les tâches et sous-tâches sont complétées
- [ ] `src/planner.py` créé avec generate_optimized_planning()
- [ ] Pipeline 3 phases orchestré: baseline → amélioration → équité
- [ ] Tests `test_planner.py` créés et passent
- [ ] Test garantie FR6: equity_gap ≤ 1 pour multiples configs
- [ ] Test configuration impossible: WARNING loggé, planning généré quand même
- [ ] Logging phases: "Phase 1/2/3" présent dans logs
- [ ] Couverture ≥95% pour src/planner.py
- [ ] `mypy --strict` passe sans erreur
- [ ] `black` et `ruff` passent sans erreur
- [ ] QA Gate YAML créé dans `docs/qa/gates/2.4-pipeline-complet.yml`
- [ ] Docstring complète avec example usage
- [ ] **Granularité:** 1 story = 1 PR (orchestration pipeline uniquement)
